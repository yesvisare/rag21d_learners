{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3.1 - Containerization with Docker\n",
    "\n",
    "**Production Deployment for RAG Systems**\n",
    "\n",
    "In this notebook:\n",
    "1. Reality Check: What Docker Solves / Doesn't\n",
    "2. Project Layout & Minimal FastAPI App\n",
    "3. Dockerfile Walkthrough\n",
    "4. docker-compose for Local Dev\n",
    "5. Image Size & Security Notes\n",
    "6. Alternatives (VMs, Bare Metal, K8s) Decision Card\n",
    "7. Troubleshooting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reality Check: What Docker Actually Does\n",
    "\n",
    "### What Docker DOES Well\n",
    "\n",
    "- **Environment consistency**: If it works on your laptop, it works in production (eliminates 60-80% of deployment issues)\n",
    "- **Horizontal scaling**: Spin up 100 containers from 1 in minutes\n",
    "- **Dependency management**: Everything defined in code, version-controlled\n",
    "\n",
    "### What Docker DOESN'T Do\n",
    "\n",
    "- **Security**: Vulnerable app in container = still vulnerable. Container isolation â‰  security solution\n",
    "- **Performance**: Adds 10-20% I/O overhead. Not ideal for ultra-low latency (<5ms)\n",
    "- **Simplicity**: Adds networking complexity. Debugging requires new skills\n",
    "\n",
    "### The Trade-offs\n",
    "\n",
    "| Gain | Cost |\n",
    "|------|------|\n",
    "| Portability | Direct metal performance |\n",
    "| Consistency | Deployment complexity |\n",
    "| Infrastructure as code | Learning curve (4-6 hours) |\n",
    "\n",
    "**Financial Cost:**\n",
    "- Docker Desktop: Free for small teams, $5-9/user/month for companies 250+\n",
    "- Image registries: $5-50/month\n",
    "- Time investment: 4-6 hours learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Check if Docker is available\nimport subprocess\nimport sys\n\ndef check_docker():\n    try:\n        result = subprocess.run(\n            ['docker', '--version'],\n            capture_output=True,\n            text=True,\n            timeout=5\n        )\n        if result.returncode == 0:\n            print(f\"âœ“ {result.stdout.strip()}\")\n            return True\n        else:\n            print(\"âœ— Docker not found\")\n            return False\n    except Exception as e:\n        print(f\"âœ— Docker check failed: {e}\")\n        print(\"\\nTo install: Visit https://docs.docker.com/get-docker/\")\n        return False\n\n# Expected:\n# âœ“ Docker version 24.0.0 (or similar)\ncheck_docker()",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Project Layout & Minimal FastAPI App\n\n### Project Structure\n\n```\nrag-production/\nâ”œâ”€â”€ m3_1_dockerize.py      # FastAPI application\nâ”œâ”€â”€ Dockerfile             # Container blueprint\nâ”œâ”€â”€ docker-compose.yml     # Multi-container orchestration\nâ”œâ”€â”€ .dockerignore         # Build exclusions\nâ”œâ”€â”€ requirements.txt      # Python dependencies\nâ””â”€â”€ data/                 # (Optional) Document corpus\n```\n\n### Key Files Created\n\nAll files are already created in this workspace:\n\n1. **m3_1_dockerize.py** - FastAPI app with health endpoint, CLI interface\n2. **Dockerfile** - Slim Python base, non-root user, healthcheck\n3. **docker-compose.yml** - Web + Redis services\n4. **requirements.txt** - Minimal dependencies (FastAPI, Uvicorn, python-dotenv)\n5. **.dockerignore** - Excludes venv, cache, env files",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verify project files exist\nimport os\n\nfiles_to_check = [\n    'm3_1_dockerize.py',\n    'Dockerfile',\n    'docker-compose.yml',\n    '.dockerignore',\n    'requirements.txt'\n]\n\nprint(\"Project files:\")\nfor f in files_to_check:\n    exists = \"âœ“\" if os.path.exists(f) else \"âœ—\"\n    print(f\"{exists} {f}\")\n\n# Expected:\n# âœ“ m3_1_dockerize.py\n# âœ“ Dockerfile\n# âœ“ docker-compose.yml\n# âœ“ .dockerignore\n# âœ“ requirements.txt",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Dockerfile Walkthrough\n\n### Our Dockerfile Strategy\n\n```dockerfile\nFROM python:3.11-slim              # Slim base (saves ~600MB vs full image)\nWORKDIR /app                       # Set working directory\nCOPY requirements.txt .            # Copy deps first (layer caching!)\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY m3_1_dockerize.py .          # Copy app code\nRUN useradd -m -u 1000 appuser    # Non-root user (security)\nUSER appuser\nHEALTHCHECK CMD curl -f http://localhost:8000/health || exit 1\nCMD [\"python\", \"m3_1_dockerize.py\", \"--serve\"]\n```\n\n### Key Optimizations\n\n1. **Layer caching**: Copy `requirements.txt` before app code â†’ only reinstall deps when requirements change\n2. **Slim base**: `python:3.11-slim` vs `python:3.11` saves 600MB+\n3. **Non-root user**: Security best practice (UID 1000)\n4. **No cache**: `--no-cache-dir` reduces image size\n5. **Health check**: Enables Docker/cloud platform health monitoring",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Inspect Dockerfile\nwith open('Dockerfile', 'r') as f:\n    content = f.read()\n    lines = content.split('\\n')\n    print(f\"Dockerfile ({len(lines)} lines):\\n\")\n    for i, line in enumerate(lines[:15], 1):  # Show first 15 lines\n        print(f\"{i:2}  {line}\")\n    if len(lines) > 15:\n        print(f\"... ({len(lines) - 15} more lines)\")\n\n# Expected:\n# Dockerfile content with FROM, WORKDIR, COPY, RUN, etc.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. docker-compose for Local Dev\n\n### Multi-Container Setup\n\nOur `docker-compose.yml` orchestrates:\n- **web**: FastAPI application (port 8000)\n- **redis**: Cache layer (port 6379)\n\n### Key Features\n\n```yaml\nservices:\n  web:\n    build: .                    # Build from Dockerfile\n    ports: [\"8000:8000\"]       # Map container port to host\n    depends_on: [redis]        # Start redis first\n    restart: unless-stopped    # Auto-restart on crash\n    networks: [rag-network]    # Custom network for inter-container comm\n    healthcheck:               # Health monitoring\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n  \n  redis:\n    image: redis:7-alpine      # Official image\n    volumes: [redis-data:/data] # Persist data\n    networks: [rag-network]\n```\n\n### Benefits\n\n- **One command startup**: `docker-compose up -d`\n- **Service discovery**: Containers use service names as hostnames\n- **Data persistence**: Named volumes survive container deletion\n- **Automatic restarts**: Production-ready failure recovery",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Show docker-compose structure\nimport yaml\n\ntry:\n    with open('docker-compose.yml', 'r') as f:\n        compose = yaml.safe_load(f)\n    \n    print(\"Services configured:\")\n    for service_name, config in compose.get('services', {}).items():\n        ports = config.get('ports', [])\n        print(f\"  â€¢ {service_name}: {ports if ports else 'no exposed ports'}\")\n    \n    print(f\"\\nVolumes: {list(compose.get('volumes', {}).keys())}\")\n    print(f\"Networks: {list(compose.get('networks', {}).keys())}\")\nexcept Exception as e:\n    print(f\"Note: Install PyYAML to parse compose file (pip install pyyaml)\")\n    print(f\"Fallback: Check docker-compose.yml manually\")\n\n# Expected:\n# Services: web, redis\n# Volumes: redis-data\n# Networks: rag-network",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Image Size & Security Notes\n\n### Image Size Comparison\n\n| Base Image | Size | Use Case |\\n|------------|------|----------|\\n| `python:3.11` | ~900MB | Development, debugging |\\n| `python:3.11-slim` | ~180MB | **Production (our choice)** |\\n| `python:3.11-alpine` | ~50MB | Ultra-minimal (compatibility issues) |\n\n**Our image**: ~250-300MB with dependencies\n\n### Security Best Practices Implemented\n\n1. **Non-root user** (`appuser`, UID 1000)\n   - Limits damage if container is compromised\n   - Standard practice for production\n\n2. **No secrets in image**\n   - Environment variables via `.env` file\n   - Never COPY `.env` into image\n\n3. **Minimal base image**\n   - Less attack surface\n   - Fewer dependencies to patch\n\n4. **Health checks**\n   - Automatic failure detection\n   - Cloud platforms use this for auto-restart\n\n### What's NOT Included (by design)\n\n- No dev tools (reduces size)\n- No shell history (security)\n- No cache files (size optimization)\n- No documentation (see .dockerignore)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Estimate image size (requires Docker)\ndef estimate_image_size():\n    try:\n        result = subprocess.run(\n            ['docker', 'images', '--format', '{{.Repository}}:{{.Tag}} {{.Size}}'],\n            capture_output=True,\n            text=True,\n            timeout=5\n        )\n        if result.returncode == 0:\n            print(\"Local Docker images:\")\n            for line in result.stdout.strip().split('\\n')[:5]:\n                print(f\"  {line}\")\n        else:\n            print(\"No Docker images found (run 'docker build' first)\")\n    except Exception as e:\n        print(f\"Docker not available: {e}\")\n        print(\"\\nExpected base image sizes:\")\n        print(\"  python:3.11-slim â†’ ~180MB\")\n        print(\"  + FastAPI/Uvicorn â†’ +70MB\")\n        print(\"  Total: ~250MB\")\n\n# Expected:\n# Image size ~250-300MB for our setup\nestimate_image_size()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Alternatives - Deployment Decision Card\n\n### Four Deployment Options\n\n| Option | Best For | Trade-off | Cost |\\n|--------|----------|-----------|------|\\n| **Docker** | 2+ devs, multi-env | Complexity â†” Consistency | $10-100/mo |\\n| **VMs** | Legacy, OS deps | Isolation â†” Resource usage | 2-3x Docker |\\n| **Bare Metal** | Solo, single server | Performance â†” Portability | Cheapest |\\n| **Kubernetes** | 50+ services | Power â†” Steep learning curve | $500-5000/mo |\n\n### Decision Framework\n\n**Choose Docker when:**\n- âœ“ Deploying to multiple environments (dev/staging/prod)\n- âœ“ Team size 2+ developers\n- âœ“ Cloud-native deployment\n- âœ“ Acceptable latency >100ms\n\n**Avoid Docker when:**\n- âœ— Solo developer, single server â†’ Use virtualenv + systemd\n- âœ— Windows-specific dependencies â†’ Use VMs\n- âœ— Ultra-low latency (<5ms) â†’ Bare metal\n- âœ— Debugging time >20% on Docker issues â†’ Tool is fighting you\n\n### When NOT to Use Docker\n\n1. **Solo + Single Server**: No environment consistency needed\n2. **Windows GUI/COM**: Linux containers won't work\n3. **HFT/Real-time**: 10-20% I/O overhead unacceptable\n\n### Full Decision Card\n\n**âœ… BENEFIT**: Environment consistency, horizontal scaling, infrastructure as code\n\n**âŒ LIMITATION**: Networking complexity, 10-20% I/O overhead, learning curve\n\n**ðŸ’° COST**: 4-6 hours learning, $10-100/mo registries, higher infra costs at scale\n\n**ðŸ¤” USE WHEN**: Multi-environment, 2+ devs, cloud deployment, >100ms latency OK\n\n**ðŸš« AVOID WHEN**: Single server, Windows deps, <5ms latency, team unfamiliar with containers",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision helper\ndef should_use_docker(team_size, num_environments, windows_only, latency_ms):\n    \\\"\\\"\\\"Quick decision logic for Docker vs alternatives.\\\"\\\"\\\"\\n    \n    score = 0\\n    reasons = []\\n    \\n    if team_size >= 2:\\n        score += 2\\n        reasons.append(\\\"âœ“ Team collaboration benefits\\\")\\n    else:\\n        reasons.append(\\\"âš  Solo dev - consider simpler options\\\")\\n    \\n    if num_environments >= 2:\\n        score += 3\\n        reasons.append(\\\"âœ“ Multi-environment consistency critical\\\")\\n    else:\\n        reasons.append(\\\"âš  Single environment - less Docker benefit\\\")\\n    \\n    if windows_only:\\n        score -= 5\\n        reasons.append(\\\"âœ— Windows-specific - use VMs instead\\\")\\n    \\n    if latency_ms < 5:\\n        score -= 3\\n        reasons.append(\\\"âœ— Ultra-low latency - bare metal better\\\")\\n    elif latency_ms < 100:\\n        reasons.append(\\\"âš  Performance-sensitive - monitor overhead\\\")\\n    else:\\n        score += 1\\n        reasons.append(\\\"âœ“ Latency tolerance acceptable\\\")\\n    \\n    print(\\\"Docker Decision Score:\\\", score)\\n    for r in reasons:\\n        print(f\\\"  {r}\\\")\\n    \\n    if score >= 4:\\n        print(\\\"\\\\nâ†’ Recommendation: Docker is a good fit\\\")\\n    elif score >= 0:\\n        print(\\\"\\\\nâ†’ Recommendation: Docker works, but weigh alternatives\\\")\\n    else:\\n        print(\\\"\\\\nâ†’ Recommendation: Consider alternatives (VMs, bare metal)\\\")\\n    \\n    return score\\n\\n# Example: 3 developers, dev+staging+prod, no Windows, 200ms latency OK\\n# Expected: Docker recommended\\nshould_use_docker(team_size=3, num_environments=3, windows_only=False, latency_ms=200)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Troubleshooting - Common Docker Failures\n\n### Failure #1: Port Already in Use\n\n**Error**: `Bind for 0.0.0.0:8000 failed: port is already allocated`\n\n**Fix**:\n```bash\n# Check what's using the port\nlsof -i :8000\n\n# Stop containers properly\ndocker-compose down\n\n# Or change port mapping\n# In docker-compose.yml: \\\"8001:8000\\\"\n```\n\n---\n\n### Failure #2: Volume Permission Errors\n\n**Error**: `PermissionError: [Errno 13] Permission denied: '/app/data'`\n\n**Fix**:\n```bash\n# Fix permissions on host\nchmod 755 ./data\nsudo chown -R 1000:1000 ./data\n\n# Or match user IDs\necho \\\"USER_ID=$(id -u)\\\" >> .env\necho \\\"GROUP_ID=$(id -g)\\\" >> .env\n```\n\n---\n\n### Failure #3: Container Networking Issues\n\n**Error**: `ConnectionError: Error connecting to redis:6379`\n\n**Fix**:\n```bash\n# Verify network\ndocker network inspect rag-network\n\n# Test connectivity\ndocker-compose exec web ping redis\n\n# Use service names, not localhost!\n# REDIS_HOST=redis  âœ“ Correct\n# REDIS_HOST=localhost  âœ— Wrong\n```\n\n---\n\n### Failure #4: Stale Image Cache\n\n**Error**: Code changes don't appear in container\n\n**Fix**:\n```bash\n# Force rebuild\ndocker-compose build --no-cache\n\n# Clean everything\ndocker-compose down -v\ndocker system prune -a\n```\n\n---\n\n### Failure #5: Out of Memory (Exit 137)\n\n**Error**: Container exits with code 137\n\n**Fix**:\n```bash\n# Monitor resources\ndocker stats\n\n# Increase memory limit in docker-compose.yml:\n# deploy:\n#   resources:\n#     limits:\n#       memory: 4G\n```\n\n---\n\n### Debug Checklist\n\n1. **Check logs**: `docker-compose logs -f`\n2. **Inspect container**: `docker inspect <container>`\n3. **Get inside**: `docker-compose exec web /bin/bash`\n4. **Check resources**: `docker stats`\n5. **Verify network**: `docker network inspect rag-network`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick Docker commands reference\\nprint(\\\"Common Docker Commands:\\\")\\nprint()\\nprint(\\\"Build & Run:\\\")\\nprint(\\\"  docker build -t rag-api:latest .\\\")\\nprint(\\\"  docker-compose up -d\\\")\\nprint(\\\"  docker-compose down\\\")\\nprint()\\nprint(\\\"Debug:\\\")\\nprint(\\\"  docker-compose logs -f web\\\")\\nprint(\\\"  docker-compose ps\\\")\\nprint(\\\"  docker stats\\\")\\nprint(\\\"  docker-compose exec web /bin/bash\\\")\\nprint()\\nprint(\\\"Clean:\\\")\\nprint(\\\"  docker-compose down -v  # Remove volumes\\\")\\nprint(\\\"  docker system prune -a  # Clean all unused\\\")\\nprint()\\nprint(\\\"Health:\\\")\\nprint(\\\"  curl http://localhost:8000/health\\\")\\nprint(\\\"  python m3_1_dockerize.py --health\\\")\\nprint()\\nprint(\\\"For full examples, see README_DOCKER.md\\\")\\n\\n# Expected:\\n# Command reference printed",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Summary & Next Steps\n\n### What We Built\n\nâœ“ FastAPI application with health endpoints  \nâœ“ Production-ready Dockerfile (slim, secure, optimized)  \nâœ“ Multi-container setup with docker-compose  \nâœ“ Redis cache layer  \nâœ“ Comprehensive troubleshooting guide  \n\n### Key Takeaways\n\n1. **Docker solves consistency**, not complexity (you trade one for the other)\n2. **Layer caching matters** - copy requirements before code\n3. **Non-root users** are security best practice\n4. **Health checks** enable auto-recovery\n5. **Service discovery** via Docker networks (use service names, not localhost)\n\n### Challenges\n\n**ðŸŸ¢ EASY**: Add PostgreSQL container for query logging  \n**ðŸŸ¡ MEDIUM**: Multi-stage Dockerfile (reduce image size 30%)  \n**ðŸ”´ HARD**: Separate dev/prod configurations with Docker Compose profiles  \n\n### Next Steps\n\n1. Deploy to Railway/Render (M3.2)\n2. API Development & Security (M3.3)\n3. Load Testing & Scaling (M3.4)\n\n### Resources\n\n- README_DOCKER.md - Full quickstart guide\n- tests_docker_sanity.py - Smoke tests\n- Docker docs: https://docs.docker.com\n\n---\n\n**End of M3.1 Notebook**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}