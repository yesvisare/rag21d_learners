{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# M2.4 ‚Äî Error Handling & Reliability\n",
    "\n",
    "**Production-ready resilience patterns for RAG systems**\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Retry strategies with exponential backoff\n",
    "- Circuit breakers for cascading failure prevention\n",
    "- Graceful degradation with fallbacks\n",
    "- Request queueing and backpressure handling\n",
    "- Real-world trade-offs and failure modes\n",
    "\n",
    "**Build Protocol**: This notebook is built incrementally. Each section is saved separately."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Purpose\n\n**Make RAG systems production-ready with error handling that actually works.**\n\nThis module teaches you to handle the 2-5% base failure rate of external APIs (OpenAI, vector databases) automatically, reducing user-facing errors by 80-95%. You'll learn patterns used by companies like Netflix, AWS, and Google to keep services running even when dependencies fail.\n\n**Real-world impact**: Transform \"Service Unavailable 503\" errors into slightly slower but functional responses.\n\n\n## Concepts Covered\n\n1. **Retry Strategy with Exponential Backoff**\n   - Smart error classification: What to retry (5xx, 429) vs what not to (4xx)\n   - Exponential delays prevent thundering herd\n   - Jitter spreads retry timing\n\n2. **Circuit Breaker Pattern**\n   - Three-state machine: CLOSED ‚Üí OPEN ‚Üí HALF_OPEN\n   - Prevents retry storms during outages\n   - Automatic recovery testing\n\n3. **Graceful Degradation**\n   - Last-known-good caching with age annotations\n   - Generic helpful messages > stack traces\n   - Stale data vs no data trade-offs\n\n4. **Request Queueing & Backpressure**\n   - Bounded queues prevent memory exhaustion\n   - Traffic spike protection\n   - Reject some vs crash all\n\n5. **Honest Trade-offs**\n   - When NOT to use each pattern\n   - Complexity vs reliability costs\n   - Production tuning guidance\n\n\n## After Completing This Module\n\nYou will be able to:\n- ‚úÖ Distinguish retryable (5xx, 429) from non-retryable (4xx) errors\n- ‚úÖ Implement circuit breakers to prevent cascading failures\n- ‚úÖ Design graceful fallback strategies for degraded operation\n- ‚úÖ Handle traffic spikes with bounded queues\n- ‚úÖ Tune resilience thresholds based on monitoring data\n- ‚úÖ Make informed decisions about when NOT to add complexity\n- ‚úÖ Deploy RAG systems with 80-95% error reduction\n\n**Production ready**: Copy patterns into your code, tune thresholds, deploy.\n\n\n## Context in Track\n\n**Prerequisites** (M1.x - M2.3):\n- M1.1-M1.4: Basic RAG (embeddings, retrieval, generation)\n- M2.1-M2.3: Chunking, vector search, evaluation\n\n**This Module** (M2.4):\nMaking RAG systems **production-ready** with error handling.\n\n**Next Steps**:\n- M3.x: Advanced RAG (hybrid search, re-ranking)\n- Production deployment with monitoring\n\n**Why This Matters**:\n- Without resilience: 2-5% base failure rate, cascading outages, crashes\n- With resilience: <0.1% error rate, graceful degradation, smooth traffic handling\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "section-1-title",
   "metadata": {},
   "source": [
    "## Section 1: Reality Check - What Resilience Solves (and Doesn't)\n",
    "\n",
    "Before diving into implementation, let's be honest about what error handling **actually solves** and what it **doesn't**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section-1-imports",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport time\nimport random\nfrom datetime import datetime\n\n# Add src to path for imports\nsys.path.insert(0, '..')\n\n# Import our resilience module from new location\nfrom src.m2_4_error_handling import (\n    RetryStrategy, with_retry, \n    CircuitBreaker, CircuitState,\n    GracefulFallbacks,\n    RequestQueue, QueueWorker,\n    ResilientOpenAIClient\n)\n\nprint(\"‚úì Resilience patterns loaded from src.m2_4_error_handling\")"
  },
  {
   "cell_type": "markdown",
   "id": "section-1-what-solves",
   "metadata": {},
   "source": [
    "### What Resilience Patterns SOLVE\n",
    "\n",
    "‚úÖ **Transient failures** - Network blips, temporary service outages  \n",
    "‚úÖ **Cascading failures** - One service down doesn't crash everything  \n",
    "‚úÖ **Rate limiting** - Automatic backoff when hitting API limits  \n",
    "‚úÖ **Load spikes** - Queue requests during traffic bursts  \n",
    "\n",
    "**Impact**: Can reduce user-facing errors by 80-95% in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-what-doesnt",
   "metadata": {},
   "source": [
    "### What Resilience Patterns DON'T SOLVE\n",
    "\n",
    "‚ùå **Bugs in your code** - Retrying a logic error won't fix it  \n",
    "‚ùå **Data corruption** - Fallbacks can't restore bad data  \n",
    "‚ùå **Permanent outages** - If the service is truly down, retries won't help  \n",
    "‚ùå **Latency** - Retries ADD latency (50-200ms overhead per retry)  \n",
    "\n",
    "**Reality**: These patterns add complexity. Use them when the trade-off makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section-1-tradeoffs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade-off visualization\n",
    "print(\"RESILIENCE TRADE-OFFS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìä Benefits:\")\n",
    "print(\"  ‚Ä¢ Error reduction: 80-95%\")\n",
    "print(\"  ‚Ä¢ User experience: Much smoother\")\n",
    "print(\"  ‚Ä¢ System stability: Prevents cascading failures\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Costs:\")\n",
    "print(\"  ‚Ä¢ Code complexity: +20-30%\")\n",
    "print(\"  ‚Ä¢ Latency overhead: +50-200ms per retry\")\n",
    "print(\"  ‚Ä¢ Infrastructure cost: +10-20% (queue memory, retry traffic)\")\n",
    "print(\"  ‚Ä¢ Development time: 8-12 hours for full stack\")\n",
    "\n",
    "print(\"\\nüéØ When to use:\")\n",
    "print(\"  ‚úì User-facing apps with 10+ users\")\n",
    "print(\"  ‚úì Production systems with external dependencies\")\n",
    "print(\"  ‚úì Services where uptime > cost\")\n",
    "\n",
    "print(\"\\nüö´ When NOT to use:\")\n",
    "print(\"  ‚úó Simple internal tools (<10 users)\")\n",
    "print(\"  ‚úó Real-time systems (<50ms SLA)\")\n",
    "print(\"  ‚úó Batch processing (failures should be investigated)\")\n",
    "\n",
    "# Expected: Trade-off table printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-decision",
   "metadata": {},
   "source": [
    "### Decision Framework\n",
    "\n",
    "**Full Resilience Stack** (This Module):  \n",
    "- Best for: User-facing apps, 10+ users\n",
    "- Time: 8-12 hours implementation\n",
    "- Cost: +10-20% infrastructure\n",
    "\n",
    "**Fail Fast + Monitoring**:  \n",
    "- Best for: Internal tools\n",
    "- Time: 2-4 hours\n",
    "- Cost: Requires on-call rotation\n",
    "\n",
    "**External Orchestration** (Service Mesh):  \n",
    "- Best for: Microservices\n",
    "- Time: 0 application code\n",
    "- Cost: Infrastructure complexity\n",
    "\n",
    "**For this module**: We're implementing the full stack because you're building production RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section-1-complete",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVED_SECTION:1\")\n",
    "print(\"Section 1 complete: Reality Check\")\n",
    "print(\"Next: Section 2 - Smart Retries\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:7\")\nprint(\"Section 7 complete: Common Failures & Decision Card\")\nprint(\"=\" * 60)\nprint(\"\\nüéâ ALL SECTIONS COMPLETE!\")\nprint(\"\\nNotebook built incrementally with 7 sections:\")\nprint(\"  1. Reality Check\")\nprint(\"  2. Smart Retries\")\nprint(\"  3. Circuit Breaker\")\nprint(\"  4. Graceful Degradation\")\nprint(\"  5. Queueing & Backpressure\")\nprint(\"  6. Putting It Together\")\nprint(\"  7. Common Failures & Decision Card\")\nprint(\"\\nYou now have a production-ready resilience stack!\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Summary: Key Takeaways\n\n1. **Resilience patterns solve transient failures**, not bugs or permanent outages\n2. **Trade-offs are real**: Complexity vs reliability, latency vs availability\n3. **Combine patterns**: Retry + Circuit Breaker + Fallback = robust system\n4. **Tune for your context**: Conservative for critical systems, aggressive for cost optimization\n5. **Monitor everything**: Track retry rates, circuit state, queue depth\n\n### Next Steps\n\n- Copy `m2_4_resilience.py` into your RAG project\n- Start with retry strategy (easiest, highest impact)\n- Add circuit breaker for production deployment\n- Tune thresholds based on your monitoring data\n\n**Remember**: The best error handling is the kind users never notice.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Production Configuration Reference\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PRODUCTION CONFIGURATION REFERENCE\")\nprint(\"=\" * 60)\n\nproduction_configs = {\n    \"Conservative (High Reliability)\": {\n        \"retry_max_retries\": 5,\n        \"retry_initial_delay\": 2.0,\n        \"cb_failure_threshold\": 3,\n        \"cb_recovery_timeout\": 120.0,\n        \"queue_max_size\": 500,\n        \"use_case\": \"Financial, healthcare, critical systems\"\n    },\n    \n    \"Balanced (Recommended Default)\": {\n        \"retry_max_retries\": 3,\n        \"retry_initial_delay\": 1.0,\n        \"cb_failure_threshold\": 5,\n        \"cb_recovery_timeout\": 60.0,\n        \"queue_max_size\": 1000,\n        \"use_case\": \"Most production RAG systems\"\n    },\n    \n    \"Aggressive (Fast Recovery)\": {\n        \"retry_max_retries\": 2,\n        \"retry_initial_delay\": 0.5,\n        \"cb_failure_threshold\": 10,\n        \"cb_recovery_timeout\": 30.0,\n        \"queue_max_size\": 2000,\n        \"use_case\": \"High-traffic, cost-sensitive, fast iteration\"\n    },\n    \n    \"Cost-Optimized (Minimize API Costs)\": {\n        \"retry_max_retries\": 1,\n        \"retry_initial_delay\": 2.0,\n        \"cb_failure_threshold\": 5,\n        \"cb_recovery_timeout\": 60.0,\n        \"queue_max_size\": 500,\n        \"use_case\": \"Development, low-budget, internal tools\"\n    }\n}\n\nfor profile, config in production_configs.items():\n    print(f\"\\n{profile}:\")\n    print(f\"  Use case: {config['use_case']}\")\n    print(f\"  Configuration:\")\n    print(f\"    ‚Ä¢ Retry max: {config['retry_max_retries']}\")\n    print(f\"    ‚Ä¢ Retry delay: {config['retry_initial_delay']}s\")\n    print(f\"    ‚Ä¢ CB threshold: {config['cb_failure_threshold']}\")\n    print(f\"    ‚Ä¢ CB timeout: {config['cb_recovery_timeout']}s\")\n    print(f\"    ‚Ä¢ Queue size: {config['queue_max_size']}\")\n\nprint(\"\\nüí° Start with 'Balanced', adjust based on monitoring data\")\n# Expected: Production config profiles",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Quick Reference: Production Thresholds\n\nCopy these battle-tested values for your production deployment:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision Card\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DECISION CARD: Choosing Resilience Patterns\")\nprint(\"=\" * 60)\n\ndecision_card = {\n    \"Retry Strategy\": {\n        \"When to use\": [\n            \"‚úì External API calls (embeddings, completions)\",\n            \"‚úì Network operations\",\n            \"‚úì Transient failures expected (<5%)\"\n        ],\n        \"When NOT to use\": [\n            \"‚úó Database writes (idempotency issues)\",\n            \"‚úó Real-time systems (<50ms SLA)\",\n            \"‚úó Already using service mesh (duplication)\"\n        ],\n        \"Cost\": \"Low - 2-3 hours implementation\",\n        \"Impact\": \"High - 80-95% error reduction\"\n    },\n    \n    \"Circuit Breaker\": {\n        \"When to use\": [\n            \"‚úì Protecting downstream services\",\n            \"‚úì Preventing cascading failures\",\n            \"‚úì Production systems with dependencies\"\n        ],\n        \"When NOT to use\": [\n            \"‚úó Single-service applications\",\n            \"‚úó Batch processing\",\n            \"‚úó When false positives unacceptable\"\n        ],\n        \"Cost\": \"Medium - 4-6 hours implementation + tuning\",\n        \"Impact\": \"High - Prevents cascading failures\"\n    },\n    \n    \"Graceful Degradation\": {\n        \"When to use\": [\n            \"‚úì User-facing applications\",\n            \"‚úì When partial functionality acceptable\",\n            \"‚úì Cached data is useful\"\n        ],\n        \"When NOT to use\": [\n            \"‚úó Financial transactions (accuracy critical)\",\n            \"‚úó Real-time data requirements\",\n            \"‚úó When stale data is worse than no data\"\n        ],\n        \"Cost\": \"Low-Medium - 3-4 hours\",\n        \"Impact\": \"Medium - Better UX during outages\"\n    },\n    \n    \"Request Queue\": {\n        \"When to use\": [\n            \"‚úì Traffic spikes expected\",\n            \"‚úì Rate-limited APIs\",\n            \"‚úì Background processing acceptable\"\n        ],\n        \"When NOT to use\": [\n            \"‚úó Latency-sensitive operations\",\n            \"‚úó Low traffic (<100 req/min)\",\n            \"‚úó When immediate response required\"\n        ],\n        \"Cost\": \"Medium - 4-5 hours\",\n        \"Impact\": \"High - Prevents thundering herd\"\n    }\n}\n\nfor pattern, details in decision_card.items():\n    print(f\"\\n{pattern}\")\n    print(f\"  When to use:\")\n    for item in details[\"When to use\"]:\n        print(f\"    {item}\")\n    print(f\"  When NOT to use:\")\n    for item in details[\"When NOT to use\"]:\n        print(f\"    {item}\")\n    print(f\"  Cost: {details['Cost']}\")\n    print(f\"  Impact: {details['Impact']}\")\n\n# Expected: Complete decision matrix printed",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Decision Card: When to Use Each Pattern\n\nUse this to decide which patterns to implement based on your constraints.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Common Failures Documentation\nprint(\"COMMON FAILURE MODES & MITIGATIONS\")\nprint(\"=\" * 60)\n\nfailures = [\n    {\n        \"name\": \"1. Retry Storm\",\n        \"problem\": \"Aggressive retries amplify load during outages\",\n        \"symptom\": \"Service goes from 90% down to 100% down due to retries\",\n        \"mitigation\": [\n            \"Use exponential backoff with jitter\",\n            \"Limit max retries (3 is usually enough)\",\n            \"Combine with circuit breaker to stop retry storm\"\n        ],\n        \"code_fix\": \"RetryStrategy(max_retries=3, jitter=True)\"\n    },\n    {\n        \"name\": \"2. Circuit Breaker False Positives\",\n        \"problem\": \"Over-sensitive thresholds reject valid requests\",\n        \"symptom\": \"Circuit opens after 2-3 transient errors, blocks traffic\",\n        \"mitigation\": [\n            \"Tune failure_threshold higher (5-10 for production)\",\n            \"Reduce recovery_timeout for faster recovery tests\",\n            \"Monitor circuit state transitions\"\n        ],\n        \"code_fix\": \"CircuitBreaker(failure_threshold=10, recovery_timeout=30.0)\"\n    },\n    {\n        \"name\": \"3. Queue Memory Exhaustion\",\n        \"problem\": \"Unbounded queues consume all memory\",\n        \"symptom\": \"System runs out of memory, crashes harder than without queue\",\n        \"mitigation\": [\n            \"ALWAYS use bounded queues\",\n            \"Set max_size based on memory constraints\",\n            \"Monitor queue depth and reject when full\"\n        ],\n        \"code_fix\": \"RequestQueue(max_size=1000)  # Bounded!\"\n    },\n    {\n        \"name\": \"4. Graceful Degradation Stuck\",\n        \"problem\": \"Fallbacks remain active after service recovers\",\n        \"symptom\": \"Users get stale cached data even when service is healthy\",\n        \"mitigation\": [\n            \"Circuit breaker naturally handles this (HALF_OPEN tests recovery)\",\n            \"Add cache TTL to expire old entries\",\n            \"Monitor fallback usage rate\"\n        ],\n        \"code_fix\": \"Circuit breaker + retry automatically recover\"\n    },\n    {\n        \"name\": \"5. Retrying Non-Retryable Errors\",\n        \"problem\": \"Wasting time/money retrying 4xx errors that won't change\",\n        \"symptom\": \"404 errors retried 3 times, tripling costs\",\n        \"mitigation\": [\n            \"Classify errors correctly (5xx = retry, 4xx = don't retry)\",\n            \"Exception: 429 (rate limit) should retry\",\n            \"Log non-retryable errors for debugging\"\n        ],\n        \"code_fix\": \"RetryStrategy with is_retryable() checks status codes\"\n    }\n]\n\nfor failure in failures:\n    print(f\"\\n{failure['name']}\")\n    print(f\"  Problem: {failure['problem']}\")\n    print(f\"  Symptom: {failure['symptom']}\")\n    print(f\"  Mitigation:\")\n    for item in failure['mitigation']:\n        print(f\"    ‚Ä¢ {item}\")\n    print(f\"  Code: {failure['code_fix']}\")\n\n# Expected: Full failure mode documentation",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 7: Common Failures & Decision Card\n\n**Reality Check**: Even with all these patterns, things can still go wrong.\n\n### 5 Common Failure Modes\n\n1. **Retry Storm**: Aggressive retries amplify load during outages\n2. **Circuit Breaker False Positives**: Over-sensitive thresholds reject valid requests\n3. **Queue Memory Exhaustion**: Unbounded queues consume all memory\n4. **Graceful Degradation Stuck**: Fallbacks remain active after recovery\n5. **Retrying Non-Retryable Errors**: Wasting time and money on 4xx errors\n\nLet's explore each one...",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:6\")\nprint(\"Section 6 complete: Putting It Together\")\nprint(\"Next: Section 7 - Common Failures & Decision Card\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 4: Traffic spike (queue protects system)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SCENARIO 4: Traffic Spike (Queue Provides Backpressure)\")\nprint(\"=\" * 60)\n\n# Simulate burst\nrag.api_failure_rate = 0.0  # API is fine, just traffic spike\nburst_questions = [f\"burst_query_{i}\" for i in range(150)]\n\naccepted = 0\nrejected = 0\n\nfor q in burst_questions:\n    result = rag.query(q)\n    if result[\"source\"] == \"rejected\":\n        rejected += 1\n    else:\n        accepted += 1\n\nprint(f\"\\nTraffic burst: {len(burst_questions)} requests\")\nprint(f\"  ‚úì Accepted: {accepted}\")\nprint(f\"  ‚úó Rejected: {rejected}\")\nprint(f\"  Success rate: {(accepted/len(burst_questions)*100):.1f}%\")\n\nprint(\"\\nüí° Queue prevents system crash during traffic spikes\")\nprint(\"   Trade-off: Some requests rejected vs complete system failure\")\n\n# Expected: Most requests handled, some rejected gracefully",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 3: Complete outage (fallback activates)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SCENARIO 3: Complete Outage (Fallbacks Activate)\")\nprint(\"=\" * 60)\n\n# First, build cache\nrag.api_failure_rate = 0.0\ncached_question = \"What is deep learning?\"\nrag.query(cached_question)  # Build cache\nprint(f\"‚úì Built cache for: {cached_question}\")\n\n# Now simulate total outage\nrag.api_failure_rate = 1.0  # 100% failure\nprint(\"\\n‚ö†Ô∏è  API completely down, triggering failures...\\n\")\n\n# Trigger circuit breaker to open\nfor i in range(6):\n    try:\n        rag.query(\"test query\")\n    except:\n        pass\n\nprint(f\"Circuit breaker state: {rag.circuit_breaker.get_state().value.upper()}\")\n\n# Query with cached data available\nresult1 = rag.query(cached_question)\nprint(f\"\\n‚úì Q: {cached_question}\")\nprint(f\"   A: {result1['answer'][:60]}...\")\nprint(f\"   Source: {result1['source']}\")\n\n# Query without cached data\nresult2 = rag.query(\"Brand new question\")\nprint(f\"\\n‚ö†Ô∏è  Q: Brand new question\")\nprint(f\"   A: {result2['answer'][:60]}...\")\nprint(f\"   Source: {result2['source']}\")\n\nprint(\"\\nüí° System degraded but functional - users see responses, not errors!\")\n# Expected: Cached response for known query, generic fallback for unknown",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 2: Transient failures (retries work)\nprint(\"=\" * 60)\nprint(\"SCENARIO 2: Transient Failures (Retries Succeed)\")\nprint(\"=\" * 60)\n\nrag.api_failure_rate = 0.6  # 60% failure rate\n\nquestion = \"What is machine learning?\"\nresult = rag.query(question)\nstatus = \"‚úì\" if not result[\"degraded_mode\"] else \"‚ö†Ô∏è \"\nprint(f\"{status} Q: {question}\")\nprint(f\"   A: {result['answer'][:60]}...\")\nprint(f\"   Source: {result['source']}, Degraded: {result['degraded_mode']}\")\n\nprint(\"\\nüí° Retries handled transient failure automatically\")\n# Expected: Query succeeds after retries",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Scenario 1: Normal operation\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SCENARIO 1: Normal Operation (No Failures)\")\nprint(\"=\" * 60)\n\nrag.api_failure_rate = 0.0\n\nfor i in range(3):\n    question = f\"What is concept_{i}?\"\n    result = rag.query(question)\n    status = \"‚úì\" if not result[\"degraded_mode\"] else \"‚ö†Ô∏è \"\n    print(f\"{status} Q: {question}\")\n    print(f\"   A: {result['answer'][:60]}...\")\n    print(f\"   Source: {result['source']}, Degraded: {result['degraded_mode']}\")\n    print()\n\nprint(\"üí° All queries succeed through normal path\")\n# Expected: 3 successful queries from live API",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo: Full resilience stack\nprint(\"DEMO: Complete Resilient RAG System\")\nprint(\"=\" * 60)\n\nclass ProductionRAG:\n    \"\"\"\n    Production-ready RAG with full resilience stack:\n    - Request queue for traffic spikes\n    - Retry strategy for transient failures\n    - Circuit breaker for cascading failure prevention\n    - Graceful fallbacks for degraded mode\n    \"\"\"\n    \n    def __init__(self):\n        self.queue = RequestQueue(max_size=100)\n        self.retry_strategy = RetryStrategy(max_retries=3, initial_delay=0.5)\n        self.circuit_breaker = CircuitBreaker(failure_threshold=5, recovery_timeout=10.0)\n        self.fallbacks = GracefulFallbacks()\n        \n        # Simulate external service state\n        self.api_failure_rate = 0.0\n    \n    def query(self, question: str) -> dict:\n        \"\"\"\n        Process query with full resilience.\n        Returns: {answer, source, degraded_mode}\n        \"\"\"\n        # Step 1: Queue (backpressure)\n        if not self.queue.enqueue(question):\n            return {\n                \"answer\": \"System is experiencing high load. Please try again shortly.\",\n                \"source\": \"rejected\",\n                \"degraded_mode\": True\n            }\n        \n        # Process from queue\n        self.queue.dequeue()\n        \n        # Step 2: Try normal flow with retry + circuit breaker\n        try:\n            def _call_with_retry():\n                def _call():\n                    # Simulate API call\n                    if random.random() < self.api_failure_rate:\n                        raise ConnectionError(\"API temporarily unavailable\")\n                    \n                    answer = f\"AI-generated answer for: {question[:40]}...\"\n                    self.fallbacks.update_cache(question, answer)\n                    return answer\n                \n                # Wrap in circuit breaker\n                return self.circuit_breaker.call(_call)\n            \n            # Execute with retry\n            answer = self.retry_strategy.execute(_call_with_retry)\n            \n            return {\n                \"answer\": answer,\n                \"source\": \"live_api\",\n                \"degraded_mode\": False\n            }\n        \n        except Exception as e:\n            # Step 3: Fallback path\n            cached = self.fallbacks.get_last_known_good(question)\n            if cached:\n                answer, age = cached\n                return {\n                    \"answer\": f\"{answer} [Cached: {age:.0f}s old]\",\n                    \"source\": \"cache\",\n                    \"degraded_mode\": True\n                }\n            \n            return {\n                \"answer\": self.fallbacks.get_generic_answer(question),\n                \"source\": \"generic_fallback\",\n                \"degraded_mode\": True\n            }\n\n# Initialize system\nrag = ProductionRAG()\nprint(\"‚úì Production RAG initialized with full resilience stack\")\nprint()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Putting It All Together - Full Resilience Stack\n\n**The Goal**: Combine all patterns into a production-ready RAG system.\n\n### Architecture\n```\nUser Query ‚Üí Queue ‚Üí Retry ‚Üí Circuit Breaker ‚Üí API Call\n                ‚Üì (if fails)\n            Fallback ‚Üí Cached Response\n```\n\nThis demonstrates a complete resilient system with all patterns working together.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:5\")\nprint(\"Section 5 complete: Queueing & Backpressure\")\nprint(\"Next: Section 6 - Putting It Together\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 3: Simulating traffic spike\nprint(\"\\nDEMO: Handling Traffic Spike\")\nprint(\"=\" * 60)\n\n# Simulate before/after queue implementation\nprint(\"\\n1. WITHOUT queue (system crashes):\")\nprint(\"  100 simultaneous requests ‚Üí System overwhelmed\")\nprint(\"  ‚úó Memory exhausted\")\nprint(\"  ‚úó Service crashes\")\nprint(\"  ‚úó 0% requests succeed\")\n\nprint(\"\\n2. WITH bounded queue (graceful handling):\")\nspike_queue = RequestQueue(max_size=50)\nburst_size = 100\naccepted_during_burst = 0\n\nfor i in range(burst_size):\n    if spike_queue.enqueue(f\"burst_req_{i}\"):\n        accepted_during_burst += 1\n\nsuccess_rate = (accepted_during_burst / burst_size) * 100\nprint(f\"  100 simultaneous requests ‚Üí Queue absorbs spike\")\nprint(f\"  ‚úì {accepted_during_burst} queued for processing\")\nprint(f\"  ‚ö†Ô∏è  {burst_size - accepted_during_burst} rejected (backpressure)\")\nprint(f\"  ‚úì Success rate: {success_rate:.0f}%\")\nprint(f\"  ‚úì System stable\")\n\nprint(\"\\n  üí° Trade-off: 50% success with queue vs 0% without!\")\nprint(\"     Users see 'Please wait' instead of crashes.\")\n\n# Expected: Queue handles spike gracefully, some requests rejected",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 2: Queue worker pattern\nprint(\"\\nDEMO: Queue Worker Processing\")\nprint(\"=\" * 60)\n\n# Create queue and worker\nwork_queue = RequestQueue(max_size=20)\nprocessed_items = []\n\ndef process_request(item):\n    \"\"\"Simulate processing a request.\"\"\"\n    time.sleep(0.1)  # Simulate work\n    result = f\"Processed: {item}\"\n    processed_items.append(result)\n    print(f\"  ‚úì {result}\")\n\nworker = QueueWorker(work_queue, process_request)\n\n# Enqueue some work\nprint(\"\\n1. Adding work to queue:\")\nfor i in range(5):\n    work_queue.enqueue(f\"task_{i}\")\nprint(f\"  Added 5 tasks (queue size: {work_queue.size()})\")\n\n# Start worker\nprint(\"\\n2. Starting worker...\")\nworker.start()\ntime.sleep(1.0)  # Let it process\n\n# Check results\nprint(f\"\\n3. Processing complete:\")\nprint(f\"  Items processed: {len(processed_items)}\")\nprint(f\"  Queue size: {work_queue.size()}\")\n\n# Clean up\nworker.stop()\nprint(\"\\n  üí° Worker processes queue in background!\")\n\n# Expected: 5 items processed, queue empty",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 1: Request queue with bounded size\nprint(\"DEMO: Request Queue with Backpressure\")\nprint(\"=\" * 60)\n\n# Create queue with small capacity for demo\nqueue = RequestQueue(max_size=10)\n\n# Simulate burst of requests\nprint(\"\\n1. Simulating traffic burst (15 requests, capacity 10):\")\nrequests = [f\"query_{i}\" for i in range(15)]\naccepted = 0\nrejected = 0\n\nfor req in requests:\n    if queue.enqueue(req):\n        accepted += 1\n    else:\n        rejected += 1\n\nprint(f\"\\n  Results:\")\nprint(f\"  ‚úì Accepted: {accepted}\")\nprint(f\"  ‚úó Rejected: {rejected} (backpressure activated)\")\nprint(f\"  Queue size: {queue.size()}/{queue.max_size}\")\n\n# Show queue stats\nprint(f\"\\n2. Queue statistics:\")\nstats = queue.stats()\nfor key, value in stats.items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\n  üí° Bounded queue prevents memory exhaustion!\")\n\n# Expected: 10 accepted, 5 rejected",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Queueing & Backpressure\n\n**The Problem**: Traffic spikes overwhelm your system (thundering herd).  \n**The Solution**: Queue requests and process at sustainable rate.\n\n### Key Concepts\n- **FIFO Queue**: Process requests in order\n- **Bounded size**: Prevent memory exhaustion\n- **Backpressure**: Reject requests when queue is full\n- **Worker pattern**: Background processing\n\n**Trade-off**: Added latency vs. system stability.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:4\")\nprint(\"Section 4 complete: Graceful Degradation\")\nprint(\"Next: Section 5 - Queueing & Backpressure\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 3: Circuit breaker + fallback integration\nprint(\"\\nDEMO: Circuit Breaker + Fallback Integration\")\nprint(\"=\" * 60)\n\nclass ResilientRAG:\n    def __init__(self):\n        self.circuit_breaker = CircuitBreaker(failure_threshold=3, recovery_timeout=5.0)\n        self.fallbacks = GracefulFallbacks()\n        self.service_is_down = False\n    \n    def query(self, question: str) -> str:\n        try:\n            # Try normal flow through circuit breaker\n            def _call():\n                if self.service_is_down:\n                    raise ConnectionError(\"RAG service unavailable\")\n                answer = f\"Fresh answer: {question[:30]}...\"\n                self.fallbacks.update_cache(question, answer)\n                return answer\n            \n            return self.circuit_breaker.call(_call)\n        \n        except Exception as e:\n            # Fallback path\n            print(f\"  ‚ö†Ô∏è  Error: {type(e).__name__}\")\n            return self.fallbacks.get_cached_or_fallback(\n                question,\n                self.fallbacks.get_generic_answer(question)\n            )\n\nrag = ResilientRAG()\n\n# Build cache\nprint(\"\\n1. Normal operation (building cache):\")\nquestion = \"What is AI?\"\nanswer = rag.query(question)\nprint(f\"  ‚úì {answer}\")\n\n# Simulate outage\nprint(\"\\n2. Service goes down (using fallback):\")\nrag.service_is_down = True\nfor i in range(4):\n    answer = rag.query(question)\n    state = rag.circuit_breaker.get_state().value\n    print(f\"  Attempt {i+1} (CB: {state}): {answer[:50]}...\")\n\nprint(\"\\n  üí° Users get cached answers instead of errors!\")\n\n# Expected: Circuit opens, fallbacks activate, users see cached data",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 2: Last-known-good with age indicator\nprint(\"\\nDEMO: Last-Known-Good Pattern\")\nprint(\"=\" * 60)\n\n# Simulate successful response\nquestion = \"What is deep learning?\"\nanswer = \"Deep learning uses neural networks with multiple layers...\"\nfallbacks.update_cache(question, answer)\n\nprint(f\"\\n1. Fresh cache entry created\")\ntime.sleep(2)  # Wait 2 seconds\n\n# Retrieve with age\nresult = fallbacks.get_last_known_good(question)\nif result:\n    cached_answer, age = result\n    print(f\"\\n2. Retrieved cached response:\")\n    print(f\"  Answer: {cached_answer[:50]}...\")\n    print(f\"  Age: {age:.1f} seconds old\")\n    print(f\"\\n  üí° User sees: '{cached_answer[:40]}...'\")\n    print(f\"     [Note: Using cached response from {age:.0f}s ago]\")\n\n# Unknown question\nresult = fallbacks.get_last_known_good(\"Unknown question?\")\nif result is None:\n    print(f\"\\n3. No cache available:\")\n    print(f\"  ‚Üí Use generic fallback message\")\n\n# Expected: Cache with age indicator, graceful handling of misses",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 1: Fallback with cached responses\nprint(\"DEMO: Graceful Degradation with Fallbacks\")\nprint(\"=\" * 60)\n\nfallbacks = GracefulFallbacks()\n\n# Simulate successful RAG queries\nprint(\"\\n1. Building cache with successful responses:\")\nquestions = [\n    \"What is machine learning?\",\n    \"How does a neural network work?\",\n    \"What is gradient descent?\"\n]\n\nfor q in questions:\n    answer = f\"[AI-generated answer about: {q}]\"\n    fallbacks.update_cache(q, answer)\n    print(f\"  ‚úì Cached: {q[:40]}...\")\n\n# Simulate service failure - use cache\nprint(\"\\n2. Service fails - using cached responses:\")\ncached_answer = fallbacks.get_cached_or_fallback(\n    questions[0],\n    \"Service temporarily unavailable\"\n)\nprint(f\"  üì¶ From cache: {cached_answer}\")\n\n# Try unknown question - use generic fallback\nprint(\"\\n3. Unknown question - generic fallback:\")\nnew_question = \"What is quantum computing?\"\nfallback_answer = fallbacks.get_cached_or_fallback(\n    new_question,\n    fallbacks.get_generic_answer(new_question)\n)\nprint(f\"  ‚ö†Ô∏è  Fallback: {fallback_answer[:80]}...\")\n\n# Expected: Cached answers served, generic fallback for unknown queries",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Graceful Degradation - Fallback Strategies\n\n**The Problem**: When services fail, users get cryptic error messages.  \n**The Solution**: Provide degraded but functional responses.\n\n### Fallback Patterns\n1. **Cached responses** - Return last-known-good answer\n2. **Generic helpful messages** - Better than a stack trace\n3. **Partial functionality** - Some features work, others degraded\n\n**Key trade-off**: Stale data vs. no data at all.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:3\")\nprint(\"Section 3 complete: Circuit Breaker\")\nprint(\"Next: Section 4 - Graceful Degradation\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 2: Circuit breaker protecting RAG system\nprint(\"\\nDEMO: Circuit-Protected RAG System\")\nprint(\"=\" * 60)\n\nclass MockOpenAIClient:\n    def __init__(self):\n        self.circuit_breaker = CircuitBreaker(failure_threshold=3, recovery_timeout=5.0)\n        self.is_down = False\n    \n    def get_embedding(self, text):\n        def _call():\n            if self.is_down:\n                raise ConnectionError(\"OpenAI API unavailable\")\n            return [random.random() for _ in range(8)]  # Mock embedding\n        \n        return self.circuit_breaker.call(_call)\n\nclient = MockOpenAIClient()\n\n# Normal operation\nprint(\"\\n1. Normal operation (service UP):\")\nfor i in range(3):\n    try:\n        emb = client.get_embedding(f\"query_{i}\")\n        print(f\"  ‚úì Embedding {i+1}: {emb[:3]}... (state: {client.circuit_breaker.get_state().value})\")\n    except Exception as e:\n        print(f\"  ‚úó {e}\")\n\n# Simulate service outage\nprint(\"\\n2. Service goes DOWN (circuit should open):\")\nclient.is_down = True\nfor i in range(5):\n    try:\n        emb = client.get_embedding(f\"query_fail_{i}\")\n        print(f\"  ‚úì Embedding {i+1}\")\n    except Exception as e:\n        state = client.circuit_breaker.get_state().value\n        print(f\"  ‚úó Call {i+1} failed (state: {state})\")\n\n# Circuit is open - requests rejected immediately\nprint(\"\\n3. Circuit OPEN - rejecting requests:\")\nprint(f\"  State: {client.circuit_breaker.get_state().value.upper()}\")\nprint(\"  üí° No more API calls attempted - preventing cascade!\")\n\n# Expected: Circuit opens after 3 failures, then rejects immediately",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 1: Circuit breaker lifecycle\nprint(\"DEMO: Circuit Breaker State Transitions\")\nprint(\"=\" * 60)\n\n# Create circuit breaker with low threshold for demo\ncb = CircuitBreaker(\n    failure_threshold=3,\n    recovery_timeout=5.0,\n    expected_exception=ConnectionError\n)\n\ndef unstable_service(should_fail=True):\n    \"\"\"Simulates an unstable service.\"\"\"\n    if should_fail:\n        raise ConnectionError(\"Service is down\")\n    return \"Service OK\"\n\nprint(f\"\\nInitial state: {cb.get_state().value}\")\n\n# Trigger failures to open circuit\nprint(\"\\n1. Causing failures to open circuit...\")\nfor i in range(4):\n    try:\n        cb.call(unstable_service, should_fail=True)\n    except ConnectionError as e:\n        print(f\"  Attempt {i+1}: Failed - State: {cb.get_state().value}\")\n\nprint(f\"\\n‚úó Circuit is now: {cb.get_state().value.upper()}\")\n\n# Try calling while circuit is open\nprint(\"\\n2. Attempting calls while circuit is OPEN...\")\ntry:\n    cb.call(unstable_service, should_fail=False)\nexcept Exception as e:\n    print(f\"  ‚úó Rejected: {e}\")\n\n# Wait for recovery timeout\nprint(f\"\\n3. Waiting {cb.recovery_timeout}s for recovery timeout...\")\ntime.sleep(cb.recovery_timeout + 0.5)\n\n# Circuit should transition to HALF_OPEN on next call\nprint(\"\\n4. Testing recovery (HALF_OPEN)...\")\ntry:\n    result = cb.call(unstable_service, should_fail=False)\n    print(f\"  ‚úì {result}\")\n    print(f\"  Circuit state: {cb.get_state().value}\")\nexcept Exception as e:\n    print(f\"  ‚úó Recovery failed: {e}\")\n\n# Expected: CLOSED ‚Üí OPEN ‚Üí HALF_OPEN ‚Üí CLOSED",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Circuit Breaker - Preventing Cascading Failures\n\n**The Problem**: When a service is down, retries make it worse (thundering herd).  \n**The Solution**: Circuit breaker stops trying after N failures, then tests recovery.\n\n### State Machine\n```\nCLOSED (normal) ‚Üí OPEN (failing) ‚Üí HALF_OPEN (testing) ‚Üí CLOSED (recovered)\n```\n\n- **CLOSED**: Normal operation, tracking failures\n- **OPEN**: Rejecting all requests (service is down)\n- **HALF_OPEN**: Testing if service recovered\n\n**Key insight**: Prevents cascading failures, but can cause false positives.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"SAVED_SECTION:2\")\nprint(\"Section 2 complete: Smart Retries\")\nprint(\"Next: Section 3 - Circuit Breaker\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 3: Retryable vs Non-retryable errors\nprint(\"\\nDEMO: Smart Error Classification\")\nprint(\"=\" * 60)\n\nclass APIError(Exception):\n    def __init__(self, status_code, message):\n        self.status_code = status_code\n        super().__init__(message)\n\ndef api_with_different_errors(error_type=\"500\"):\n    \"\"\"Simulate API with different error types.\"\"\"\n    if error_type == \"500\":\n        raise APIError(500, \"Internal Server Error - Retryable\")\n    elif error_type == \"429\":\n        raise APIError(429, \"Rate Limit - Retryable\")\n    elif error_type == \"404\":\n        raise APIError(404, \"Not Found - Non-retryable\")\n    elif error_type == \"401\":\n        raise APIError(401, \"Unauthorized - Non-retryable\")\n    return \"Success\"\n\nstrategy = RetryStrategy(max_retries=2, initial_delay=0.3)\n\n# Test retryable error (500)\nprint(\"\\nTest 1: 500 Server Error (should retry)\")\ntry:\n    # Simulate recovery on 2nd attempt\n    attempt = [0]\n    def call_500():\n        attempt[0] += 1\n        if attempt[0] < 2:\n            raise APIError(500, \"Server error\")\n        return \"Recovered!\"\n    result = strategy.execute(call_500)\n    print(f\"‚úì {result}\")\nexcept Exception as e:\n    print(f\"‚úó {e}\")\n\n# Test non-retryable error (404)\nprint(\"\\nTest 2: 404 Not Found (should NOT retry)\")\ntry:\n    strategy.execute(api_with_different_errors, error_type=\"404\")\nexcept APIError as e:\n    print(f\"‚úó Immediately failed (no retries): {e}\")\n\nprint(\"\\nüí° Key insight: Retrying 404s wastes time and money!\")\n# Expected: 500 retries, 404 fails immediately",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 2: Retry decorator (cleaner syntax)\nprint(\"\\nDEMO: Using @with_retry Decorator\")\nprint(\"=\" * 60)\n\n@with_retry(max_retries=3, initial_delay=0.5, jitter=True)\ndef fetch_embeddings(text: str):\n    \"\"\"Simulate embedding API call.\"\"\"\n    if random.random() < 0.6:  # 60% failure rate\n        raise ConnectionError(\"Embedding API temporarily unavailable\")\n    return f\"Embedding[1536] for: {text[:30]}...\"\n\n# Use the decorated function\nprint(\"\\nFetching embeddings...\")\ntry:\n    embedding = fetch_embeddings(\"What is machine learning?\")\n    print(f\"‚úì {embedding}\")\nexcept Exception as e:\n    print(f\"‚úó Failed: {e}\")\n\n# Expected: Automatic retries, cleaner code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Demo 1: Basic retry with exponential backoff\nprint(\"DEMO: Retry with Exponential Backoff\")\nprint(\"=\" * 60)\n\ndef flaky_api_call(failure_rate=0.7, call_id=\"test\"):\n    \"\"\"Simulates a flaky API that fails randomly.\"\"\"\n    if random.random() < failure_rate:\n        raise ConnectionError(f\"API call {call_id} failed (simulated)\")\n    return f\"Success: {call_id}\"\n\n# Create retry strategy\nstrategy = RetryStrategy(\n    max_retries=3,\n    initial_delay=0.5,  # Short for demo\n    exponential_base=2.0,\n    jitter=True\n)\n\n# Try calling the flaky API\nprint(\"\\nAttempting flaky API call (70% failure rate)...\")\ntry:\n    result = strategy.execute(flaky_api_call, failure_rate=0.7, call_id=\"demo-001\")\n    print(f\"\\n‚úì Final result: {result}\")\nexcept Exception as e:\n    print(f\"\\n‚úó All retries exhausted: {e}\")\n\n# Expected: Shows 1-4 attempts with exponential delays",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Smart Retries with Exponential Backoff\n\n**The Problem**: Network calls fail ~2-5% of the time due to transient issues.  \n**The Solution**: Retry with increasing delays + jitter to prevent thundering herd.\n\n### Key Concepts\n- **Exponential backoff**: Each retry waits longer (1s ‚Üí 2s ‚Üí 4s)\n- **Jitter**: Add randomness to prevent synchronized retries\n- **Retryable vs non-retryable**: Don't retry 4xx errors (except 429)",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbconvert": 4,
 "nbformat_minor": 5
}