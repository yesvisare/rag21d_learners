{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3.1 - Containerization with Docker\n",
    "\n",
    "**Production Deployment for RAG Systems**\n",
    "\n",
    "In this notebook:\n",
    "1. Reality Check: What Docker Solves / Doesn't\n",
    "2. Project Layout & Minimal FastAPI App\n",
    "3. Dockerfile Walkthrough\n",
    "4. docker-compose for Local Dev\n",
    "5. Image Size & Security Notes\n",
    "6. Alternatives (VMs, Bare Metal, K8s) Decision Card\n",
    "7. Troubleshooting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reality Check: What Docker Actually Does\n",
    "\n",
    "### What Docker DOES Well\n",
    "\n",
    "- **Environment consistency**: If it works on your laptop, it works in production (eliminates 60-80% of deployment issues)\n",
    "- **Horizontal scaling**: Spin up 100 containers from 1 in minutes\n",
    "- **Dependency management**: Everything defined in code, version-controlled\n",
    "\n",
    "### What Docker DOESN'T Do\n",
    "\n",
    "- **Security**: Vulnerable app in container = still vulnerable. Container isolation â‰  security solution\n",
    "- **Performance**: Adds 10-20% I/O overhead. Not ideal for ultra-low latency (<5ms)\n",
    "- **Simplicity**: Adds networking complexity. Debugging requires new skills\n",
    "\n",
    "### The Trade-offs\n",
    "\n",
    "| Gain | Cost |\n",
    "|------|------|\n",
    "| Portability | Direct metal performance |\n",
    "| Consistency | Deployment complexity |\n",
    "| Infrastructure as code | Learning curve (4-6 hours) |\n",
    "\n",
    "**Financial Cost:**\n",
    "- Docker Desktop: Free for small teams, $5-9/user/month for companies 250+\n",
    "- Image registries: $5-50/month\n",
    "- Time investment: 4-6 hours learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Check if Docker is available\nimport subprocess\nimport sys\n\ndef check_docker():\n    try:\n        result = subprocess.run(\n            ['docker', '--version'],\n            capture_output=True,\n            text=True,\n            timeout=5\n        )\n        if result.returncode == 0:\n            print(f\"âœ“ {result.stdout.strip()}\")\n            return True\n        else:\n            print(\"âœ— Docker not found\")\n            return False\n    except Exception as e:\n        print(f\"âœ— Docker check failed: {e}\")\n        print(\"\\nTo install: Visit https://docs.docker.com/get-docker/\")\n        return False\n\n# Expected:\n# âœ“ Docker version 24.0.0 (or similar)\ncheck_docker()",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Project Layout & Minimal FastAPI App\n\n### Project Structure\n\n```\nrag-production/\nâ”œâ”€â”€ app.py                 # FastAPI application\nâ”œâ”€â”€ requirements.txt       # Python dependencies\nâ”œâ”€â”€ .env.example          # Environment template\nâ”œâ”€â”€ docker/\nâ”‚   â”œâ”€â”€ Dockerfile        # Multi-stage container blueprint\nâ”‚   â”œâ”€â”€ docker-compose.yml # Multi-container orchestration\nâ”‚   â””â”€â”€ .dockerignore     # Build exclusions\nâ”œâ”€â”€ notebooks/\nâ”‚   â””â”€â”€ M3_1_Containerization_with_Docker.ipynb\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ test_smoke.py     # FastAPI TestClient tests\nâ”‚   â””â”€â”€ test_docker_sanity.py # Docker setup tests\nâ””â”€â”€ scripts/\n    â””â”€â”€ run_local.ps1     # Local development script\n```\n\n### Key Files Created\n\nAll files follow TVH's standard per-module layout:\n\n1. **app.py** - FastAPI app with health endpoint, CLI interface\n2. **docker/Dockerfile** - Multi-stage build, non-root user, healthcheck\n3. **docker/docker-compose.yml** - Web + Redis services with health checks\n4. **requirements.txt** - Dependencies (FastAPI, Uvicorn, pytest, httpx)\n5. **docker/.dockerignore** - Excludes venv, cache, env files\n6. **tests/** - pytest-compatible test suite",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verify project files exist\nimport os\n\nfiles_to_check = [\n    '../app.py',\n    '../docker/Dockerfile',\n    '../docker/docker-compose.yml',\n    '../docker/.dockerignore',\n    '../requirements.txt',\n    '../tests/test_smoke.py'\n]\n\nprint(\"Project files:\")\nfor f in files_to_check:\n    exists = \"âœ“\" if os.path.exists(f) else \"âœ—\"\n    display_name = f.replace('../', '')\n    print(f\"{exists} {display_name}\")\n\n# Expected:\n# âœ“ app.py\n# âœ“ docker/Dockerfile\n# âœ“ docker/docker-compose.yml\n# âœ“ docker/.dockerignore\n# âœ“ requirements.txt\n# âœ“ tests/test_smoke.py",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Dockerfile Walkthrough\n\n### Multi-Stage Build Strategy\n\n```dockerfile\n# Stage 1: Builder\nFROM python:3.11-slim AS builder\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --user -r requirements.txt\n\n# Stage 2: Runtime\nFROM python:3.11-slim\nCOPY --from=builder /root/.local /root/.local  # Copy only packages\nCOPY app.py .                                    # Copy app code\nRUN useradd -m -u 1000 appuser                  # Non-root user\nUSER 1000:1000                                   # Switch to non-root\nHEALTHCHECK CMD curl -f http://localhost:8000/health || exit 1\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n### Key Optimizations\n\n1. **Multi-stage build**: Separates build dependencies from runtime (smaller final image)\n2. **Layer caching**: Copy `requirements.txt` before app code â†’ only reinstall deps when requirements change\n3. **Slim base**: `python:3.11-slim` vs `python:3.11` saves 600MB+\n4. **Non-root user**: Security best practice (UID 1000)\n5. **No cache**: `--no-cache-dir` reduces image size\n6. **Health check**: Enables Docker/cloud platform health monitoring\n7. **Direct uvicorn**: Use uvicorn directly instead of Python wrapper (faster)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Inspect Dockerfile\nwith open('../docker/Dockerfile', 'r') as f:\n    content = f.read()\n    lines = content.split('\\n')\n    print(f\"Dockerfile ({len(lines)} lines):\\n\")\n    for i, line in enumerate(lines[:20], 1):  # Show first 20 lines\n        print(f\"{i:2}  {line}\")\n    if len(lines) > 20:\n        print(f\"... ({len(lines) - 20} more lines)\")\n\n# Expected:\n# Multi-stage Dockerfile with builder and runtime stages",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. docker-compose for Local Dev\n\n### Multi-Container Setup\n\nOur `docker-compose.yml` orchestrates:\n- **web**: FastAPI application (port 8000)\n- **redis**: Cache layer (port 6379)\n\n### Key Features\n\n```yaml\nservices:\n  web:\n    build:\n      context: ..               # Build from parent directory\n      dockerfile: docker/Dockerfile\n    ports: [\"8000:8000\"]\n    depends_on:\n      redis:\n        condition: service_healthy  # Wait for redis to be healthy\n    restart: unless-stopped\n    networks: [rag-network]\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n  \n  redis:\n    image: redis:7-alpine\n    volumes: [redis-data:/data]\n    networks: [rag-network]\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]  # Redis health check\n```\n\n### Benefits\n\n- **One command startup**: `docker compose up -d` (from docker/ directory)\n- **Service discovery**: Containers use service names as hostnames\n- **Data persistence**: Named volumes survive container deletion\n- **Health-based dependencies**: Web waits for redis to be healthy\n- **Automatic restarts**: Production-ready failure recovery",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Show docker-compose structure\nimport yaml\n\ntry:\n    with open('../docker/docker-compose.yml', 'r') as f:\n        compose = yaml.safe_load(f)\n    \n    print(\"Services configured:\")\n    for service_name, config in compose.get('services', {}).items():\n        ports = config.get('ports', [])\n        depends_on = config.get('depends_on', {})\n        healthcheck = 'healthcheck' in config\n        print(f\"  â€¢ {service_name}: ports={ports}, health={healthcheck}, deps={list(depends_on.keys()) if depends_on else []}\")\n    \n    print(f\"\\nVolumes: {list(compose.get('volumes', {}).keys())}\")\n    print(f\"Networks: {list(compose.get('networks', {}).keys())}\")\nexcept Exception as e:\n    print(f\"Note: Install PyYAML to parse compose file (pip install pyyaml)\")\n    print(f\"Fallback: Check docker/docker-compose.yml manually\")\n\n# Expected:\n# Services: web (with health + deps on redis), redis (with health)\n# Volumes: redis-data\n# Networks: rag-network",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Image Size & Security Notes\n\n### Image Size Comparison\n\n| Base Image | Size | Use Case |\n|------------|------|----------|\n| `python:3.11` | ~900MB | Development, debugging |\n| `python:3.11-slim` | ~180MB | **Production (our choice)** |\n| `python:3.11-alpine` | ~50MB | Ultra-minimal (compatibility issues) |\n\n**Our multi-stage image**: ~200-250MB with dependencies (optimized!)\n\n### Security Best Practices Implemented\n\n1. **Multi-stage build**\n   - Separates build-time and runtime dependencies\n   - Smaller attack surface\n   \n2. **Non-root user** (`appuser`, UID 1000)\n   - Limits damage if container is compromised\n   - Standard practice for production\n\n3. **No secrets in image**\n   - Environment variables via `.env` file\n   - Never COPY `.env` into image\n\n4. **Minimal base image**\n   - Less attack surface\n   - Fewer dependencies to patch\n\n5. **Health checks**\n   - Automatic failure detection\n   - Cloud platforms use this for auto-restart\n\n### What's NOT Included (by design)\n\n- No dev tools (reduces size)\n- No shell history (security)\n- No cache files (size optimization)\n- No documentation (see .dockerignore)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Estimate image size (requires Docker)\ndef estimate_image_size():\n    try:\n        result = subprocess.run(\n            ['docker', 'images', '--format', '{{.Repository}}:{{.Tag}} {{.Size}}'],\n            capture_output=True,\n            text=True,\n            timeout=5\n        )\n        if result.returncode == 0:\n            print(\"Local Docker images:\")\n            for line in result.stdout.strip().split('\\n')[:5]:\n                print(f\"  {line}\")\n        else:\n            print(\"No Docker images found (run 'docker build' first)\")\n    except Exception as e:\n        print(f\"Docker not available: {e}\")\n        print(\"\\nExpected base image sizes:\")\n        print(\"  python:3.11-slim â†’ ~180MB\")\n        print(\"  + FastAPI/Uvicorn â†’ +70MB\")\n        print(\"  Total: ~250MB\")\n\n# Expected:\n# Image size ~250-300MB for our setup\nestimate_image_size()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Alternatives - Deployment Decision Card\n\n### Four Deployment Options\n\n| Option | Best For | Trade-off | Cost |\\n|--------|----------|-----------|------|\\n| **Docker** | 2+ devs, multi-env | Complexity â†” Consistency | $10-100/mo |\\n| **VMs** | Legacy, OS deps | Isolation â†” Resource usage | 2-3x Docker |\\n| **Bare Metal** | Solo, single server | Performance â†” Portability | Cheapest |\\n| **Kubernetes** | 50+ services | Power â†” Steep learning curve | $500-5000/mo |\n\n### Decision Framework\n\n**Choose Docker when:**\n- âœ“ Deploying to multiple environments (dev/staging/prod)\n- âœ“ Team size 2+ developers\n- âœ“ Cloud-native deployment\n- âœ“ Acceptable latency >100ms\n\n**Avoid Docker when:**\n- âœ— Solo developer, single server â†’ Use virtualenv + systemd\n- âœ— Windows-specific dependencies â†’ Use VMs\n- âœ— Ultra-low latency (<5ms) â†’ Bare metal\n- âœ— Debugging time >20% on Docker issues â†’ Tool is fighting you\n\n### When NOT to Use Docker\n\n1. **Solo + Single Server**: No environment consistency needed\n2. **Windows GUI/COM**: Linux containers won't work\n3. **HFT/Real-time**: 10-20% I/O overhead unacceptable\n\n### Full Decision Card\n\n**âœ… BENEFIT**: Environment consistency, horizontal scaling, infrastructure as code\n\n**âŒ LIMITATION**: Networking complexity, 10-20% I/O overhead, learning curve\n\n**ðŸ’° COST**: 4-6 hours learning, $10-100/mo registries, higher infra costs at scale\n\n**ðŸ¤” USE WHEN**: Multi-environment, 2+ devs, cloud deployment, >100ms latency OK\n\n**ðŸš« AVOID WHEN**: Single server, Windows deps, <5ms latency, team unfamiliar with containers",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision helper\ndef should_use_docker(team_size, num_environments, windows_only, latency_ms):\n    \\\"\\\"\\\"Quick decision logic for Docker vs alternatives.\\\"\\\"\\\"\\n    \n    score = 0\\n    reasons = []\\n    \\n    if team_size >= 2:\\n        score += 2\\n        reasons.append(\\\"âœ“ Team collaboration benefits\\\")\\n    else:\\n        reasons.append(\\\"âš  Solo dev - consider simpler options\\\")\\n    \\n    if num_environments >= 2:\\n        score += 3\\n        reasons.append(\\\"âœ“ Multi-environment consistency critical\\\")\\n    else:\\n        reasons.append(\\\"âš  Single environment - less Docker benefit\\\")\\n    \\n    if windows_only:\\n        score -= 5\\n        reasons.append(\\\"âœ— Windows-specific - use VMs instead\\\")\\n    \\n    if latency_ms < 5:\\n        score -= 3\\n        reasons.append(\\\"âœ— Ultra-low latency - bare metal better\\\")\\n    elif latency_ms < 100:\\n        reasons.append(\\\"âš  Performance-sensitive - monitor overhead\\\")\\n    else:\\n        score += 1\\n        reasons.append(\\\"âœ“ Latency tolerance acceptable\\\")\\n    \\n    print(\\\"Docker Decision Score:\\\", score)\\n    for r in reasons:\\n        print(f\\\"  {r}\\\")\\n    \\n    if score >= 4:\\n        print(\\\"\\\\nâ†’ Recommendation: Docker is a good fit\\\")\\n    elif score >= 0:\\n        print(\\\"\\\\nâ†’ Recommendation: Docker works, but weigh alternatives\\\")\\n    else:\\n        print(\\\"\\\\nâ†’ Recommendation: Consider alternatives (VMs, bare metal)\\\")\\n    \\n    return score\\n\\n# Example: 3 developers, dev+staging+prod, no Windows, 200ms latency OK\\n# Expected: Docker recommended\\nshould_use_docker(team_size=3, num_environments=3, windows_only=False, latency_ms=200)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Troubleshooting - Common Docker Failures\n\n### Failure #1: Port Already in Use\n\n**Error**: `Bind for 0.0.0.0:8000 failed: port is already allocated`\n\n**Fix**:\n```bash\n# Check what's using the port\nlsof -i :8000\n\n# Stop containers properly\ndocker-compose down\n\n# Or change port mapping\n# In docker-compose.yml: \\\"8001:8000\\\"\n```\n\n---\n\n### Failure #2: Volume Permission Errors\n\n**Error**: `PermissionError: [Errno 13] Permission denied: '/app/data'`\n\n**Fix**:\n```bash\n# Fix permissions on host\nchmod 755 ./data\nsudo chown -R 1000:1000 ./data\n\n# Or match user IDs\necho \\\"USER_ID=$(id -u)\\\" >> .env\necho \\\"GROUP_ID=$(id -g)\\\" >> .env\n```\n\n---\n\n### Failure #3: Container Networking Issues\n\n**Error**: `ConnectionError: Error connecting to redis:6379`\n\n**Fix**:\n```bash\n# Verify network\ndocker network inspect rag-network\n\n# Test connectivity\ndocker-compose exec web ping redis\n\n# Use service names, not localhost!\n# REDIS_HOST=redis  âœ“ Correct\n# REDIS_HOST=localhost  âœ— Wrong\n```\n\n---\n\n### Failure #4: Stale Image Cache\n\n**Error**: Code changes don't appear in container\n\n**Fix**:\n```bash\n# Force rebuild\ndocker-compose build --no-cache\n\n# Clean everything\ndocker-compose down -v\ndocker system prune -a\n```\n\n---\n\n### Failure #5: Out of Memory (Exit 137)\n\n**Error**: Container exits with code 137\n\n**Fix**:\n```bash\n# Monitor resources\ndocker stats\n\n# Increase memory limit in docker-compose.yml:\n# deploy:\n#   resources:\n#     limits:\n#       memory: 4G\n```\n\n---\n\n### Debug Checklist\n\n1. **Check logs**: `docker-compose logs -f`\n2. **Inspect container**: `docker inspect <container>`\n3. **Get inside**: `docker-compose exec web /bin/bash`\n4. **Check resources**: `docker stats`\n5. **Verify network**: `docker network inspect rag-network`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick Docker commands reference\nprint(\"Common Docker Commands:\")\nprint()\nprint(\"Build & Run (from docker/ directory):\")\nprint(\"  cd docker\")\nprint(\"  docker compose build\")\nprint(\"  docker compose up -d\")\nprint(\"  docker compose down\")\nprint()\nprint(\"Debug:\")\nprint(\"  docker compose logs -f web\")\nprint(\"  docker compose ps\")\nprint(\"  docker stats\")\nprint(\"  docker compose exec web /bin/bash\")\nprint()\nprint(\"Clean:\")\nprint(\"  docker compose down -v  # Remove volumes\")\nprint(\"  docker system prune -a  # Clean all unused\")\nprint()\nprint(\"Health:\")\nprint(\"  curl http://localhost:8000/health\")\nprint(\"  python app.py --health  # From project root\")\nprint()\nprint(\"Tests:\")\nprint(\"  pytest  # From project root\")\nprint()\nprint(\"For full examples, see README.md\")\n\n# Expected:\n# Command reference printed",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Summary & Next Steps\n\n### What We Built\n\nâœ“ FastAPI application with health endpoints (app.py)\nâœ“ Multi-stage Dockerfile (optimized, secure)\nâœ“ docker-compose with health-based dependencies\nâœ“ Redis cache layer with persistence\nâœ“ pytest-compatible test suite\nâœ“ TVH standard per-module layout\n\n### Key Takeaways\n\n1. **Multi-stage builds** reduce image size and attack surface\n2. **Health checks** enable automatic recovery and dependency ordering\n3. **Non-root users** are security best practice\n4. **Layer caching matters** - copy requirements before code\n5. **Service discovery** via Docker networks (use service names, not localhost)\n6. **depends_on with condition** ensures proper startup order\n\n### Challenges\n\n**ðŸŸ¢ EASY**: Add PostgreSQL container for query logging\n**ðŸŸ¡ MEDIUM**: Implement production vs development docker-compose profiles\n**ðŸ”´ HARD**: Add nginx reverse proxy with SSL termination\n\n### Next Steps\n\n1. Run tests: `pytest` from project root\n2. Deploy to Railway/Render (M3.2)\n3. API Development & Security (M3.3)\n4. Load Testing & Scaling (M3.4)\n\n### Resources\n\n- README.md - Full quickstart guide with learning arc\n- tests/test_smoke.py - FastAPI TestClient examples\n- Docker docs: https://docs.docker.com\n\n---\n\n**End of M3.1 Notebook**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}