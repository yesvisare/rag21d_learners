{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# M4.1 ‚Äî Hybrid Search (Sparse + Dense)\n\n## Learning Arc\n\n**Purpose**\nThis module teaches production-grade hybrid search combining BM25 keyword matching with dense vector embeddings. You'll learn when hybrid search justifies its complexity overhead and when simpler approaches suffice.\n\n**Concepts Covered**\n- BM25 sparse retrieval for exact keyword matching\n- Dense vector embeddings for semantic understanding\n- Alpha weighting to balance sparse and dense scores\n- Reciprocal Rank Fusion (RRF) for rank-based merging\n- Smart query analysis to auto-tune search strategy\n- Cost-benefit analysis of latency, complexity, and accuracy trade-offs\n\n**After Completing**\nYou will be able to:\n- Implement hybrid search with configurable merge strategies\n- Tune alpha weights based on query characteristics  \n- Decide when hybrid search adds value vs overhead\n- Debug common issues (normalization, namespace mismatches)\n- Estimate costs and latency for production deployments\n- Choose between alpha weighting and RRF for your use case\n\n**Context in Track**\n- **Prerequisite**: M1 (Vector Databases), M2 (Cost Optimization)\n- **Builds on**: Dense embeddings from M1.4, cost awareness from M2.1\n- **Prepares for**: M4.2 (Beyond Free Tier), M4.3 (Portfolio Projects)\n- **Real-world**: E-commerce search, technical docs, mixed-content platforms"
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Prereq Check & Reality Check\n",
    "\n",
    "Before diving into hybrid search, let's verify our environment and set realistic expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plbqwj89na",
   "source": "### 1.1 Dependency Check\n\nFirst, we'll check that all required libraries for this module (like `openai`, `pinecone`, and `rank_bm25`) are installed in your environment. If any are missing, a `pip install` command will be suggested.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section1-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Check library availability\n",
    "required_libs = {\n",
    "    'openai': '1.46.0',\n",
    "    'rank_bm25': '0.2.2',\n",
    "    'nltk': '3.9.1',\n",
    "    'numpy': '1.26.4',\n",
    "    'pinecone': '3.0.0'\n",
    "}\n",
    "\n",
    "print(\"üì¶ Checking Dependencies...\\n\")\n",
    "missing = []\n",
    "\n",
    "for lib, version in required_libs.items():\n",
    "    try:\n",
    "        if lib == 'rank_bm25':\n",
    "            import rank_bm25\n",
    "            print(f\"‚úì {lib} installed\")\n",
    "        elif lib == 'pinecone':\n",
    "            from pinecone import Pinecone\n",
    "            print(f\"‚úì {lib} installed\")\n",
    "        else:\n",
    "            __import__(lib)\n",
    "            print(f\"‚úì {lib} installed\")\n",
    "    except ImportError:\n",
    "        print(f\"‚úó {lib} MISSING (required: {version})\")\n",
    "        missing.append(lib)\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n‚ö† Install missing: pip install {' '.join(missing)}\")\n",
    "else:\n",
    "    print(\"\\n‚úì All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vt34aev5id",
   "source": "### 1.2 API Key & Environment Setup\n\nThis cell loads your `.env` file and verifies your `OPENAI_API_KEY` and `PINECONE_API_KEY`. The notebook will run in **\"FULL\"** mode if keys are found, or **\"STUB\"** mode (with limited features) if they are missing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section1-env",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"üîë Checking API Keys...\\n\")\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY', '')\n",
    "pinecone_key = os.getenv('PINECONE_API_KEY', '')\n",
    "\n",
    "# Check OpenAI\n",
    "if openai_key and openai_key.startswith('sk-'):\n",
    "    print(f\"‚úì OpenAI API key found ({openai_key[:8]}...)\")\n",
    "    OPENAI_OK = True\n",
    "else:\n",
    "    print(\"‚úó OpenAI API key missing or invalid\")\n",
    "    OPENAI_OK = False\n",
    "\n",
    "# Check Pinecone\n",
    "if pinecone_key and len(pinecone_key) > 10:\n",
    "    print(f\"‚úì Pinecone API key found ({pinecone_key[:8]}...)\")\n",
    "    PINECONE_OK = True\n",
    "else:\n",
    "    print(\"‚úó Pinecone API key missing\")\n",
    "    PINECONE_OK = False\n",
    "\n",
    "# Set mode\n",
    "if OPENAI_OK and PINECONE_OK:\n",
    "    MODE = \"FULL\"\n",
    "    print(\"\\nüöÄ Running in FULL mode with API access\")\n",
    "else:\n",
    "    MODE = \"STUB\"\n",
    "    print(\"\\nüîß Running in STUB mode (limited functionality)\")\n",
    "    print(\"   ‚Üí BM25 and smart_alpha will work\")\n",
    "    print(\"   ‚Üí Dense/Pinecone features will use stubs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2qzbxqqbjjs",
   "source": "### 1.3 Reality Check: When to Use Hybrid Search\n\nBefore we build, it's critical to know *why*. Hybrid search adds complexity. This \"reality check\" outlines the specific scenarios where it provides significant value (e.g., mixed queries, product SKUs) and when it's better to avoid it (e.g., small datasets, pure conversational search).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section1-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reality Check: When to use hybrid search\n",
    "print(\"üìä Reality Check: Hybrid Search Trade-offs\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ USE HYBRID SEARCH WHEN:\")\n",
    "print(\"  ‚Ä¢ Mixed queries: natural language + technical terms/codes\")\n",
    "print(\"  ‚Ä¢ Product catalogs with SKUs, IDs, or model numbers\")\n",
    "print(\"  ‚Ä¢ Need 40-60% improvement on exact match accuracy\")\n",
    "print(\"  ‚Ä¢ Reducing false positives from pure semantic search\")\n",
    "\n",
    "print(\"\\n‚ùå AVOID HYBRID SEARCH WHEN:\")\n",
    "print(\"  ‚Ä¢ Corpus < 1,000 docs (overhead not justified)\")\n",
    "print(\"  ‚Ä¢ Need P99 latency < 50ms (hybrid adds 80-120ms)\")\n",
    "print(\"  ‚Ä¢ 90%+ purely conversational queries (dense-only better)\")\n",
    "print(\"  ‚Ä¢ Limited resources (2x indexes to maintain)\")\n",
    "\n",
    "print(\"\\nüí∞ COST CONSIDERATIONS:\")\n",
    "print(\"  ‚Ä¢ Development: 12-16 hours proper implementation\")\n",
    "print(\"  ‚Ä¢ Scale: In-memory BM25 viable for <100K docs\")\n",
    "print(\"  ‚Ä¢ Beyond 100K: Need Elasticsearch ($150-500/month)\")\n",
    "print(\"  ‚Ä¢ Query cost: 2+ API calls per search\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\n‚úì Prereqs verified. Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section1-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìù SAVED_SECTION: 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z19db58aih",
   "source": "---\n## Section 2: BM25 vs Dense Recap\n\nUnderstanding the strengths and weaknesses of each approach is crucial for effective hybrid search.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "j0cvu628cgm",
   "source": "### 2.1 BM25 vs Dense Comparison Table\n\nLet's compare the two retrieval approaches side-by-side to understand their complementary strengths and weaknesses.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ivgua2ng4y",
   "source": "# Comparison table\nimport pandas as pd\n\ncomparison_data = {\n    'Aspect': [\n        'Algorithm',\n        'Strengths',\n        'Weaknesses',\n        'Best For',\n        'Latency',\n        'Cost'\n    ],\n    'BM25 (Sparse)': [\n        'Term frequency + IDF + doc length',\n        'Exact matches, technical terms, IDs/SKUs',\n        'No semantic understanding, synonym issues',\n        'Keyword search, product codes, exact phrases',\n        '<1ms (in-memory)',\n        'Free (in-memory)'\n    ],\n    'Dense (Embeddings)': [\n        'Neural network vector similarity',\n        'Semantic understanding, synonyms, context',\n        'May miss exact terms, hallucination risk',\n        'Natural language, conceptual queries',\n        '50-100ms (API + vector DB)',\n        '$0.0001/query (embedding cost)'\n    ]\n}\n\ndf = pd.DataFrame(comparison_data)\nprint(\"üìä BM25 vs Dense Comparison\\\\n\")\nprint(df.to_string(index=False))\n\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"Key Insight: Hybrid combines BOTH approaches to cover weaknesses!\")\nprint(\"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ol5b39qif4o",
   "source": "### 2.2 Quick BM25 Demo\n\nHere's a hands-on demo of BM25 in action. This works even in STUB mode (no API keys required) since BM25 runs entirely in-memory.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lwdcz0ry1hn",
   "source": "# Quick BM25 demo (works in STUB mode)\nfrom rank_bm25 import BM25Okapi\nfrom nltk.tokenize import word_tokenize\nimport nltk\n\n# Download NLTK data if needed\ntry:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt', quiet=True)\n\n# Sample documents\ndocs = [\n    \"Python is a high-level programming language\",\n    \"Machine learning algorithms use neural networks\",\n    \"Product SKU ABC-12345 is available in stock\",\n    \"Natural language processing enables text understanding\",\n    \"Order number 67890 shipped yesterday\"\n]\n\n# Tokenize and build BM25 index\ntokenized = [word_tokenize(doc.lower()) for doc in docs]\nbm25 = BM25Okapi(tokenized)\n\nprint(\"üîç BM25 Examples:\\\\n\")\n\n# Test queries\ntest_queries = [\n    \"ABC-12345\",           # Exact code match\n    \"programming python\",  # Keywords\n    \"understanding text\"   # Synonym/reorder\n]\n\nfor query in test_queries:\n    tokenized_query = word_tokenize(query.lower())\n    scores = bm25.get_scores(tokenized_query)\n    top_idx = scores.argmax()\n    \n    print(f\"Query: '{query}'\")\n    print(f\"  ‚Üí Top match: {docs[top_idx][:60]}...\")\n    print(f\"  ‚Üí Score: {scores[top_idx]:.4f}\\\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yjm5ie0wmn",
   "source": "print(\"\\nüìù SAVED_SECTION: 2\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cy6y740uzoo",
   "source": "---\n## Section 3: Index Build (Dense + Sparse)\n\nLet's build both indexes using our HybridSearchEngine class.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "wz132gpl4t",
   "source": "### 3.1 Initialize HybridSearchEngine\n\nWe'll import and initialize our `HybridSearchEngine` class, which manages both BM25 and dense vector search. The engine auto-detects API keys and adjusts functionality accordingly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "t6qz4xjw0u",
   "source": "# Import our hybrid search module\nimport sys\nsys.path.insert(0, '..')\n\nfrom m4_1_hybrid_search import HybridSearchEngine\n\n# Initialize engine\nengine = HybridSearchEngine(\n    openai_api_key=os.getenv('OPENAI_API_KEY'),\n    pinecone_api_key=os.getenv('PINECONE_API_KEY'),\n    index_name=os.getenv('PINECONE_INDEX_NAME', 'hybrid-search'),\n    namespace='m4-demo'\n)\n\nprint(\"‚úì HybridSearchEngine initialized\")\nprint(f\"  Mode: {MODE}\")\nprint(f\"  Namespace: {engine.namespace}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kkjj1fmzdip",
   "source": "### 3.2 Create Sample Dataset\n\nLet's create a sample dataset with a mix of technical content (SKUs, model numbers) and natural language descriptions. This diversity is perfect for demonstrating hybrid search benefits.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "209tl3c6o28",
   "source": "# Sample dataset: Mix of technical and natural language\ndocuments = [\n    {\n        \"id\": \"doc1\",\n        \"text\": \"Python is a versatile programming language used for web development, data science, and automation.\",\n        \"metadata\": {\"category\": \"programming\", \"difficulty\": \"beginner\"}\n    },\n    {\n        \"id\": \"doc2\",\n        \"text\": \"Machine learning algorithms like neural networks can recognize patterns in large datasets.\",\n        \"metadata\": {\"category\": \"ai\", \"difficulty\": \"advanced\"}\n    },\n    {\n        \"id\": \"doc3\",\n        \"text\": \"Product SKU ABC-12345 is a wireless keyboard with RGB backlight. Model number KBD-2024.\",\n        \"metadata\": {\"category\": \"product\", \"in_stock\": True}\n    },\n    {\n        \"id\": \"doc4\",\n        \"text\": \"Natural language processing enables computers to understand human text and speech.\",\n        \"metadata\": {\"category\": \"ai\", \"difficulty\": \"intermediate\"}\n    },\n    {\n        \"id\": \"doc5\",\n        \"text\": \"Order #67890 contains 3 items: laptop, mouse, and headphones. Shipped via FedEx.\",\n        \"metadata\": {\"category\": \"order\", \"shipped\": True}\n    },\n    {\n        \"id\": \"doc6\",\n        \"text\": \"Deep learning models require GPU acceleration for efficient training on large corpora.\",\n        \"metadata\": {\"category\": \"ai\", \"difficulty\": \"advanced\"}\n    },\n    {\n        \"id\": \"doc7\",\n        \"text\": \"Monitor model MON-4K-27 has 3840x2160 resolution. Part number DISPLAY-789.\",\n        \"metadata\": {\"category\": \"product\", \"in_stock\": False}\n    },\n    {\n        \"id\": \"doc8\",\n        \"text\": \"JavaScript frameworks like React enable building interactive user interfaces for web applications.\",\n        \"metadata\": {\"category\": \"programming\", \"difficulty\": \"intermediate\"}\n    }\n]\n\nprint(f\"üìö Created {len(documents)} sample documents\")\nprint(f\"   Categories: {set(d['metadata']['category'] for d in documents)}\")\nprint(f\"\\\\nSample document:\")\nprint(f\"  ID: {documents[0]['id']}\")\nprint(f\"  Text: {documents[0]['text'][:60]}...\")\nprint(f\"  Metadata: {documents[0]['metadata']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hzpml22qv1r",
   "source": "### 3.3 Build Both Indexes\n\nNow we'll build both the BM25 (sparse) and Pinecone (dense) indexes. BM25 builds instantly in-memory, while dense indexing requires embedding generation and Pinecone upsert (10-30 seconds in FULL mode).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "c153ucn810n",
   "source": "# Step 1: Build BM25 index (works in all modes)\nprint(\"üî® Building BM25 index...\")\nengine.add_documents(documents)\nprint(\"‚úì BM25 index built!\\\\n\")\n\n# Step 2: Build dense index (requires API keys)\nif MODE == \"FULL\":\n    print(\"üî® Building dense index (Pinecone)...\")\n    print(\"   This will generate embeddings and upsert to Pinecone...\")\n    print(\"   (This may take 10-30 seconds)\\\\n\")\n    \n    try:\n        engine.upsert_to_pinecone(batch_size=4)\n        print(\"\\\\n‚úì Dense index built!\")\n    except Exception as e:\n        print(f\"\\\\n‚ö† Dense indexing failed: {e}\")\n        print(\"   Falling back to STUB mode for dense search\")\n        MODE = \"STUB\"\nelse:\n    print(\"üîß STUB mode: Skipping Pinecone upsert\")\n    print(\"   Dense search will return empty results\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "85uqqfconw9",
   "source": "print(\"\\nüìù SAVED_SECTION: 3\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "sik6witx8nb",
   "source": "---\n## Section 4: Alpha Tuning (0.2 / 0.5 / 0.8)\n\nAlpha controls the weight between dense and sparse retrieval:\n- `alpha = 1.0`: Pure dense (semantic only)\n- `alpha = 0.5`: Equal weighting\n- `alpha = 0.0`: Pure sparse (BM25 only)\n\nLet's test different alpha values on various query types.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "gkz2qefvr1",
   "source": "### 4.1 Smart Alpha Detection\n\nThe `smart_alpha()` function analyzes query patterns (SKU codes, technical terms, natural language) and automatically suggests the optimal alpha value. Let's see it in action.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7rexnh4izyt",
   "source": "# Test queries with different characteristics\ntest_queries = [\n    {\n        \"query\": \"ABC-12345\",\n        \"type\": \"Exact SKU\",\n        \"expected\": \"Should favor BM25 (low alpha)\"\n    },\n    {\n        \"query\": \"understanding human language\",\n        \"type\": \"Natural language\",\n        \"expected\": \"Should favor dense (high alpha)\"\n    },\n    {\n        \"query\": \"GPU training models\",\n        \"type\": \"Mixed technical + concepts\",\n        \"expected\": \"Balanced alpha\"\n    }\n]\n\nprint(\"üß™ Testing Smart Alpha Detection\\\\n\")\nprint(\"=\"*80)\n\nfor test in test_queries:\n    alpha = engine.smart_alpha(test[\"query\"])\n    print(f\"\\\\nQuery: '{test['query']}'\")\n    print(f\"Type: {test['type']}\")\n    print(f\"Smart Alpha: {alpha:.2f}\")\n    print(f\"Expected: {test['expected']}\")\n    \nprint(\"\\\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1qqqbfmcbub",
   "source": "### 4.2 Alpha Comparison Test\n\nLet's test the same query with different alpha values (0.2, 0.5, 0.8) to see how the weighting affects result rankings. Lower alpha favors BM25, higher favors dense embeddings.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "w771vc3f4xe",
   "source": "# Compare alpha values on BM25-only query (STUB mode compatible)\nprint(\"üìä Alpha Comparison on BM25 Search\\\\n\")\nprint(\"Query: 'keyboard RGB backlight'\\\\n\")\n\nquery = \"keyboard RGB backlight\"\nalphas = [0.2, 0.5, 0.8]\n\n# Get BM25 results for comparison\nbm25_results = engine.search_bm25(query, top_k=3)\n\nprint(\"BM25 Results (baseline):\")\nfor i, result in enumerate(bm25_results, 1):\n    print(f\"  {i}. [{result['id']}] {result['text'][:50]}... (score={result['score']:.4f})\")\n\nprint(\"\\\\n\" + \"-\"*80)\n\nif MODE == \"FULL\":\n    print(\"\\\\nHybrid Results with Different Alphas:\\\\n\")\n    \n    for alpha in alphas:\n        print(f\"Alpha = {alpha} ({'sparse' if alpha < 0.4 else 'balanced' if alpha < 0.7 else 'dense'}):\")\n        results = engine.hybrid_search_alpha(query, top_k=3, alpha=alpha)\n        \n        for i, result in enumerate(results, 1):\n            print(f\"  {i}. [{result['id']}] {result['text'][:50]}... (score={result['score']:.4f})\")\n        print()\nelse:\n    print(\"\\\\n‚ö† STUB mode: Dense features unavailable\")\n    print(\"   In FULL mode, you would see how alpha affects ranking!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "tccet9911ws",
   "source": "print(\"\\nüìù SAVED_SECTION: 4\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "r614pzrc7nr",
   "source": "---\n## Section 5: RRF Merge Demo\n\nReciprocal Rank Fusion (RRF) is an alternative to alpha weighting that:\n- Doesn't require score normalization\n- Is more robust to score scale differences\n- Reduces need for tuning\n\nFormula: `rrf_score = sum(1 / (k + rank + 1))`",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "i0owemav71",
   "source": "### 5.1 Manual RRF Calculation\n\nLet's manually calculate RRF scores to understand the algorithm. RRF uses rank positions (not scores) to combine results, which makes it more robust than alpha weighting.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "i48vxt9smy",
   "source": "# Demonstrate RRF calculation manually\nprint(\"üî¢ RRF Calculation Example\\\\n\")\nprint(\"=\"*80)\n\n# Simulate two ranked lists\ndense_ranks = [\"doc2\", \"doc4\", \"doc6\", \"doc1\"]  # Dense retrieval results\nsparse_ranks = [\"doc3\", \"doc1\", \"doc2\", \"doc5\"]  # BM25 results\n\nk = 60  # RRF constant\n\nprint(\"Dense ranking:  \", dense_ranks)\nprint(\"Sparse ranking: \", sparse_ranks)\nprint(f\"\\\\nRRF constant k = {k}\\\\n\")\n\n# Calculate RRF scores\nrrf_scores = {}\n\nprint(\"Calculating RRF scores:\\\\n\")\n\nfor rank, doc_id in enumerate(dense_ranks):\n    score = 1.0 / (k + rank + 1)\n    rrf_scores[doc_id] = rrf_scores.get(doc_id, 0) + score\n    print(f\"  {doc_id} (dense rank {rank}): +{score:.6f}\")\n\nprint()\n\nfor rank, doc_id in enumerate(sparse_ranks):\n    score = 1.0 / (k + rank + 1)\n    old_score = rrf_scores.get(doc_id, 0)\n    rrf_scores[doc_id] = old_score + score\n    print(f\"  {doc_id} (sparse rank {rank}): +{score:.6f} ‚Üí total={rrf_scores[doc_id]:.6f}\")\n\n# Sort by RRF score\nsorted_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n\nprint(f\"\\\\nFinal RRF Ranking:\\\\n\")\nfor i, (doc_id, score) in enumerate(sorted_docs, 1):\n    in_both = doc_id in dense_ranks and doc_id in sparse_ranks\n    print(f\"  {i}. {doc_id}: {score:.6f} {'‚úì (in both)' if in_both else ''}\")\n\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"\\\\nKey Insight: Documents in BOTH lists get boosted!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f2lzxiafh7",
   "source": "### 5.2 Alpha vs RRF Side-by-Side\n\nNow let's compare alpha-weighted and RRF merge strategies on the same query. Note how they may produce different rankings despite using the same underlying searches.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "npl98mcfb78",
   "source": "# Compare Alpha vs RRF on actual query\nprint(\"‚öñÔ∏è  Alpha vs RRF Comparison\\\\n\")\nprint(\"=\"*80)\n\nquery = \"machine learning algorithms\"\n\nprint(f\"Query: '{query}'\\\\n\")\n\n# BM25 only\nprint(\"BM25 Results:\")\nbm25_results = engine.search_bm25(query, top_k=3)\nfor i, r in enumerate(bm25_results, 1):\n    print(f\"  {i}. [{r['id']}] {r['text'][:55]}...\")\n\nif MODE == \"FULL\":\n    # Alpha weighted\n    print(\"\\\\nAlpha Weighted (alpha=0.5):\")\n    alpha_results = engine.hybrid_search_alpha(query, top_k=3, alpha=0.5)\n    for i, r in enumerate(alpha_results, 1):\n        print(f\"  {i}. [{r['id']}] {r['text'][:55]}...\")\n    \n    # RRF\n    print(\"\\\\nRRF Merged:\")\n    rrf_results = engine.hybrid_search_rrf(query, top_k=3, k=60)\n    for i, r in enumerate(rrf_results, 1):\n        print(f\"  {i}. [{r['id']}] {r['text'][:55]}...\")\n    \n    print(\"\\\\n\" + \"=\"*80)\n    print(\"\\\\nNote: RRF and Alpha may produce different rankings!\")\n    print(\"RRF is generally more stable and requires less tuning.\")\nelse:\n    print(\"\\\\n‚ö† STUB mode: RRF requires dense search\")\n    print(\"   Enable FULL mode to see RRF in action!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "u65bl24755",
   "source": "print(\"\\nüìù SAVED_SECTION: 5\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5nh9s1q0u2i",
   "source": "---\n## Section 6: When NOT to Use Hybrid (Cost/Latency/Complexity)\n\nHybrid search isn't always the answer. Let's analyze when the overhead isn't justified.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "6t6mypts489",
   "source": "### 6.1 Cost-Benefit Scenarios\n\nLet's analyze four realistic scenarios to determine when hybrid search justifies its overhead. Each scenario considers corpus size, traffic, and query characteristics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "nox9b0u410i",
   "source": "# Cost-Benefit Analysis\nprint(\"üí∞ Hybrid Search Cost-Benefit Analysis\\\\n\")\nprint(\"=\"*80)\n\nscenarios = [\n    {\n        \"name\": \"Small Documentation Site\",\n        \"corpus_size\": 500,\n        \"queries_per_day\": 100,\n        \"query_type\": \"90% natural language\",\n        \"recommendation\": \"‚ùå SKIP HYBRID\",\n        \"reason\": \"Corpus too small, dense-only sufficient\"\n    },\n    {\n        \"name\": \"E-commerce Product Catalog\",\n        \"corpus_size\": 50000,\n        \"queries_per_day\": 10000,\n        \"query_type\": \"Mix: 40% SKU/codes, 60% natural\",\n        \"recommendation\": \"‚úÖ USE HYBRID\",\n        \"reason\": \"Exact match critical, high query diversity\"\n    },\n    {\n        \"name\": \"Real-time Chat Support\",\n        \"corpus_size\": 5000,\n        \"queries_per_day\": 5000,\n        \"query_type\": \"80% conversational\",\n        \"recommendation\": \"‚ùå SKIP HYBRID\",\n        \"reason\": \"P50 latency < 50ms required, dense sufficient\"\n    },\n    {\n        \"name\": \"Technical Documentation\",\n        \"corpus_size\": 20000,\n        \"queries_per_day\": 2000,\n        \"query_type\": \"Mix: 50% API names, 50% concepts\",\n        \"recommendation\": \"‚úÖ USE HYBRID\",\n        \"reason\": \"Exact API names + semantic understanding needed\"\n    }\n]\n\nfor scenario in scenarios:\n    print(f\"\\\\n{scenario['name']}:\")\n    print(f\"  Corpus: {scenario['corpus_size']:,} docs\")\n    print(f\"  Traffic: {scenario['queries_per_day']:,} queries/day\")\n    print(f\"  Query mix: {scenario['query_type']}\")\n    print(f\"  {scenario['recommendation']}\")\n    print(f\"  ‚Üí {scenario['reason']}\")\n\nprint(\"\\\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "gtctau2zw07",
   "source": "### 6.2 Complexity & Performance Analysis\n\nHybrid search doubles maintenance complexity (two indexes to sync). Let's break down the latency overhead and cost implications in detail.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eokniyuaj8",
   "source": "# Complexity and Maintenance Burden\nprint(\"üîß Complexity & Maintenance Analysis\\\\n\")\nprint(\"=\"*80)\n\nprint(\"\\\\nüìà COMPLEXITY INCREASES:\\\\n\")\ncomplexity_factors = [\n    (\"Two indexes to maintain\", \"Every doc update ‚Üí 2 writes\"),\n    (\"Sync challenges\", \"Consistency between BM25 and vector DB\"),\n    (\"Alpha tuning\", \"Requires query analysis and testing\"),\n    (\"Performance monitoring\", \"Track both systems separately\"),\n    (\"Cost optimization\", \"Balance API calls vs accuracy\")\n]\n\nfor factor, impact in complexity_factors:\n    print(f\"  ‚Ä¢ {factor}\")\n    print(f\"    ‚Üí {impact}\")\n\nprint(\"\\\\n‚è±Ô∏è  LATENCY OVERHEAD:\\\\n\")\nprint(\"  Dense-only:   ~50-80ms\")\nprint(\"  + BM25:       +5-10ms (negligible)\")\nprint(\"  + Merge:      +10-20ms (normalization + combine)\")\nprint(\"  + Network:    +20-30ms (additional variance)\")\nprint(\"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\nprint(\"  Total Hybrid: ~85-140ms\")\n\nprint(\"\\\\nüíµ COST BREAKDOWN (per 1000 queries):\\\\n\")\nprint(\"  Dense-only:\")\nprint(\"    Embeddings:  1000 √ó $0.0001 = $0.10\")\nprint(\"    Pinecone:    ~$0.05\")\nprint(\"    Total:       $0.15\")\nprint(\"\\\\n  Hybrid:\")\nprint(\"    Embeddings:  1000 √ó $0.0001 = $0.10\")\nprint(\"    Pinecone:    ~$0.05\")\nprint(\"    BM25 (mem):  $0.00\")\nprint(\"    Total:       $0.15 (same cost!)\")\nprint(\"\\\\n  Note: Cost similar, but complexity DOUBLES\")\n\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"\\\\n‚úÖ Decision Rule: Use hybrid ONLY if accuracy gain > 30%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5vaufpe7jok",
   "source": "print(\"\\nüìù SAVED_SECTION: 6\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lddccp1gkdf",
   "source": "---\n## Section 7: Troubleshooting\n\nCommon issues and solutions when implementing hybrid search.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "9rz0ouwdxlp",
   "source": "### 7.1 Common Issues & Solutions\n\nHere's a comprehensive troubleshooting guide covering the most common hybrid search implementation issues, their symptoms, and proven solutions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "79lhrz0kjh3",
   "source": "# Common Issues and Solutions\nprint(\"üîç Hybrid Search Troubleshooting Guide\\\\n\")\nprint(\"=\"*80)\n\nissues = [\n    {\n        \"problem\": \"BM25 scores dominating hybrid results\",\n        \"symptoms\": \"Alpha weighting seems ineffective, all results favor keyword matches\",\n        \"solution\": \"Normalize scores BEFORE merging. Check max_bm25 != 0 handling.\",\n        \"code\": \"scores_norm = scores / max(scores) if max(scores) > 0 else scores\"\n    },\n    {\n        \"problem\": \"Dense search returns nothing\",\n        \"symptoms\": \"Hybrid search = pure BM25, Pinecone shows 0 results\",\n        \"solution\": \"Check: (1) Index exists, (2) Namespace matches, (3) Vectors uploaded\",\n        \"code\": \"index.describe_index_stats() # Check vector count per namespace\"\n    },\n    {\n        \"problem\": \"RRF results same as BM25\",\n        \"symptoms\": \"RRF merge appears to ignore dense results\",\n        \"solution\": \"Dense search may be failing silently. Verify API keys and quota.\",\n        \"code\": \"try: dense_results = search_dense() except Exception as e: log(e)\"\n    },\n    {\n        \"problem\": \"Smart alpha always returns same value\",\n        \"symptoms\": \"Query analysis not detecting patterns correctly\",\n        \"solution\": \"Review regex patterns. Test with clear examples (SKUs, natural text).\",\n        \"code\": \"print(smart_alpha('ABC-123'))  # Should be low (~0.3)\"\n    },\n    {\n        \"problem\": \"High latency (>200ms P50)\",\n        \"symptoms\": \"Hybrid search too slow for production\",\n        \"solution\": \"Parallelize dense + sparse search. Cache embeddings. Use async.\",\n        \"code\": \"asyncio.gather(search_dense(), search_sparse())\"\n    },\n    {\n        \"problem\": \"Different results every query\",\n        \"symptoms\": \"Non-deterministic rankings for same query\",\n        \"solution\": \"Pinecone approximate search varies. Use exact match for testing.\",\n        \"code\": \"index.query(..., include_metadata=True, exact=True)\"\n    }\n]\n\nfor i, issue in enumerate(issues, 1):\n    print(f\"\\\\n{i}. {issue['problem']}\")\n    print(f\"   Symptoms: {issue['symptoms']}\")\n    print(f\"   Solution: {issue['solution']}\")\n    print(f\"   Code: {issue['code']}\")\n\nprint(\"\\\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w847y0170p",
   "source": "### 7.2 Diagnostic Tests\n\nLet's run a quick diagnostic suite to verify your hybrid search engine is configured correctly. This will check BM25, smart alpha, dense search (if available), and document counts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "04g5o20ngxe3",
   "source": "# Quick Diagnostic Test\nprint(\"ü©∫ Running Diagnostics...\\\\n\")\n\n# Test 1: BM25 working?\ntry:\n    test_bm25 = engine.search_bm25(\"test\", top_k=1)\n    print(\"‚úì BM25 index functional\")\nexcept Exception as e:\n    print(f\"‚úó BM25 error: {e}\")\n\n# Test 2: Smart alpha working?\ntry:\n    alpha_natural = engine.smart_alpha(\"how does this work\")\n    alpha_code = engine.smart_alpha(\"SKU-12345\")\n    \n    if alpha_natural > alpha_code:\n        print(f\"‚úì Smart alpha working (natural={alpha_natural:.2f}, code={alpha_code:.2f})\")\n    else:\n        print(f\"‚ö† Smart alpha may have issues (natural={alpha_natural:.2f}, code={alpha_code:.2f})\")\nexcept Exception as e:\n    print(f\"‚úó Smart alpha error: {e}\")\n\n# Test 3: Dense search configured?\nif MODE == \"FULL\":\n    try:\n        test_dense = engine.search_dense(\"test\", top_k=1)\n        if test_dense:\n            print(f\"‚úì Dense search returning results ({len(test_dense)} found)\")\n        else:\n            print(\"‚ö† Dense search returning empty (check namespace/vectors)\")\n    except Exception as e:\n        print(f\"‚úó Dense search error: {e}\")\nelse:\n    print(\"‚äò Dense search not configured (STUB mode)\")\n\n# Test 4: Document count\nprint(f\"\\\\nüìä Indexed documents: {len(engine.documents)}\")\nprint(f\"   BM25 tokens: {len(engine.tokenized_docs)} docs tokenized\")\n\nif MODE == \"FULL\" and engine.index:\n    try:\n        stats = engine.index.describe_index_stats()\n        namespace_count = stats.namespaces.get(engine.namespace, {}).get('vector_count', 0)\n        print(f\"   Pinecone vectors: {namespace_count} in namespace '{engine.namespace}'\")\n    except:\n        print(\"   Pinecone stats unavailable\")\n\nprint(\"\\\\n‚úì Diagnostics complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ij599zs8vuh",
   "source": "print(\"\\nüìù SAVED_SECTION: 7\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "poo0h8m5sxm",
   "source": "---\n## üéâ Notebook Complete!\n\nYou've completed M4.1 - Hybrid Search! \n\n**Key Takeaways:**\n1. ‚úÖ Hybrid combines BM25 + dense for better coverage\n2. ‚úÖ Alpha weighting (0.0-1.0) balances sparse vs dense\n3. ‚úÖ RRF is more robust and requires less tuning\n4. ‚úÖ Use hybrid when query diversity demands both approaches\n5. ‚úÖ Skip hybrid if corpus < 1K or queries 90%+ natural language\n\n**Next Steps:**\n- Test with your own data\n- Monitor accuracy improvements\n- Profile latency and costs\n- Consider async implementation for production\n\nSee `README.md` for architecture details and `tests_hybrid_merge.py` for test examples.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}